---
title: "HMC Learn"
output: pdf_document
vignette: >
  %\VignetteIndexEntry{HMC_learn}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
header-includes:
  - \usepackage{setspace}
  - \doublespacing
  - \usepackage{amsmath}
  - \usepackage{algorithm}
  - \usepackage{algpseudocode}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
# library(hmclearn)
```

# Introduction

Hamiltonian Monte Carlo (HMC) has emerged as a general purpose tool for Bayesian practitioners.  A key advantage of HMC over more traditional Markov Chain Monte Carlo (MCMC) algorithms is its improved computational efficiency in fitting high-dimensional models.   While the algorithm itself is not difficult to program, the substantial number of tuning parameters can be daunting to those unfamiliar with the theory behind the method.  Until recently, practical access to HMC was limited to individuals with both the mathematical background to understand the algorithm and the programming skill to implement the simulation in a high-performance environment.   

Modern Bayesian software such as Stan has made HMC accessible to practitioners who are comfortable with any one of a variety of well-known programming platforms (e.g. R, Python, Matlab).  The Stan language is similar in style to WinBUGS, which is familiar to many Bayesian statisticians.  The software translates Stan code to a lower-level language to maximize speed and efficiency.  In addition, Stan automates the challenging process of tuning the many parameters in HMC.  As a result, Stan has succeeded in making HMC accessible to many Bayesian practitioners around the world in both academia and industry.  

While Stan and other high-performance software (e.g. PyMC, Edward) provide enormous practical value to analysts, the intuition of how HMC works can be lost in the process of fitting models.  HMC can appear to be an opaque, "black-box" algorithm behind the sophisticated automation.  This is an unfortunate consequence.  While understanding HMC is not necessary to use production software, intuition behind the method can be helpful both in fine-tuning the simulation process and in instilling confidence in the results.  

The purpose of this paper is to introduce HMC to analysts using R software only, an open-source statistical environment that is familiar to many.  While many excellent introductions to HMC are available on a conceptual level, this paper will focus on learning HMC by doing.  Familiarity with popular MCMC algorithms such as Metropolis-Hastings (MH) is helpful, but not required.  A companion R package called hmclearn contains the R code for all of the functions used in this introduction is freely available to download.  

# MCMC Basic Concepts

We consider $n$ observations from a simple random sample $\pmb{X} = (X_1, ..., X_n)$, where each element is independent and identically distributed (iid).  From this sample, we want to fit the distribution of our k-dimensional parameter of interest $\Theta = (\theta_1, ..., \theta_k)$.  The posterior distribution $p(\Theta | \pmb{X})$ can be written as a function of the Likelihood $p(\pmb{X} | \Theta)$ and prior $p(\Theta)$ using Bayes formula.  

$$
\begin{aligned}
p(\Theta | \pmb{X}) &= \frac{p(\pmb{X}|\Theta)p(\Theta)}{\int p(\pmb{X}|\Theta)p(\Theta)d\Theta} \\
&\propto p(\pmb{X}|\Theta) p(\Theta)
\end{aligned}
$$

In many practical data analyses, the integral in the denominator cannot be evaluated directly.  Since the denominator is constant with respect to $\Theta$, only the unnormalized posterior $p(\pmb{X} | \Theta)$ is available.  

## Metropolis-Hastings

The first widely-used MCMC method capable of simulating directly from $p(\pmb{X} | \Theta)$ is called the Metropolis algorithm, originating in the 1950's from an application to statistical physics.  Nearly two decades later, Hastings generalized the algorithm, which is now called Metropolis-Hastings (MH).  We begin with a brief introduction to MH since HMC builds on many similar concepts.  

The objective of MH is to simulate values of $\Theta$ that accurately reflect the posterior density $p(\Theta | \pmb{X})$.  For brevity, we will shorten our notation of the posterior as $p(\Theta)$. The Markov chain simulates values from this density in sequence from $t = 1, .., N$, provided some starting point $\Theta^{(0)}$ which is typically provided by the analyst or the computer program.  
MH defines a transition probability that produces a Markov chain that is ergodic and satisfies detailed balance.  Values of $\Theta^{(t)}$ in the chain are defined in part by a proposal density, which we define as $q(\Theta^{\text{PROP}} | \Theta^{t-1})$.  Here, $\Theta^{\text{PROP}}$ is a proposal for the next value in the chain.  This proposal density is conditioned on the previously stored value $\Theta^{(t-1)}$.  A variety of proposal functions can be used, with random walk proposals being a common choice.  We now outline the MH algorithm in full.  

\begin{algorithm}
\caption{Metropolis-Hastings}\label{Metropolis-Hastings}
\begin{algorithmic}[1]
\Procedure{MH}{$\theta^{(0)}, \pi^{*}(\theta), q(\theta^{(x)}|\theta^{(y)}), N$} 
   \State Calculate $\pi^{*}(\theta^{(0)})$ \Comment{Initial value for posterior}
   \For{$t = 1, ..., N$}\Comment{Repeat simulation $N$ times}
      \State $\theta^{\text{PROP}} \gets q(\theta^{\text{PROP}} | \theta^{(t-1)})$ \Comment{Randomly sample proposal}
      \State $u \gets U(0, 1)$ \Comment{Randomly sample from a uniform density, 0 to 1}
      \State $\alpha = \min\left(1, \frac{\pi(\theta^{\text{PROP}})q(\theta^{\text{PROP}}|\theta^{(t-1)})}{\pi(\theta^{(t-1)})q(\theta^{(t-1)}|\theta^{\text{PROP}})} \right)$ \Comment{Calculate acceptance proposal probability}
      \State If $\alpha < u$, then $\theta^{(t)} \gets \theta^{\text{PROP}}$.  Otherwise, $\theta^{(t)} \gets \theta^{(t-1)}$ \Comment{Select proposal or previous value}
   \EndFor\label{markovendfor}
   \State \textbf{return} $\theta^{(1)} ... \theta^{(N)}$ \Comment{Return simulated values of $\theta$ from the unnormalized posterior}
\EndProcedure
\end{algorithmic}
\end{algorithm}

Each proposal in MH is accepted at probability

$$
\alpha = \min\left(1, \frac{p(\Theta^{\text{PROP}})q(\Theta^{\text{PROP}}|\Theta^{(t-1)})}{p(\Theta^{(t-1)})q(\Theta^{(t-1)}|\Theta^{\text{PROP}})} \right)
$$

which simplifies when $q(\Theta^{PROP} | \Theta^{(t-1)})$ is symmetric (i.e. the Metropolis algorithm)

$$
\alpha = \min\left(1, \frac{p(\Theta^{\text{PROP}})}{p(\Theta^{(t-1)})} \right).
$$

Recall that the denominator of the posterior is constant with respect to $\Theta$.  As such, the ratio of posterior densities at two different points $\Theta^{PROP}$ and $\Theta^{(t-1)}$ can be formulated even when the denominator is unknown (i.e. the constants in the denominator cancel).  

Intuition into why MH works can be obtained by examining the acceptance ratio $\alpha$ closely.  Two different outcomes are possible depending on the value of the posterior at the proposed $\Theta^{PROP}$:

\begin{enumerate}
\item If $p(\Theta^{PROP}) \geq p(\Theta^{(t-1)})$, then the posterior has a higher density at the proposed value of $\Theta$ than at the previous point in the chain $t-1$.  When this occurs, the proposal is always accepted (i.e. at probability 1).  
\item If $p(\Theta^{PROP}) < p(\Theta^{(t-1)})$, then the posterior has a lower density at the proposed value of $\Theta$ than at the previous point in the chain.  When this occurs, we accept the proposal at random based on the ratio $0 < \alpha < 1$.  If the proposal is not accepted, then the proposal is discarded and the Markov chain remains in place $\Theta^{t} := \Theta^{(t-1)}$.  
\end{enumerate}

As such, MH tends to sample more points in the region of higher posterior values.  However, the tails of the posterior are also sampled based on acceptance ratio.  Given enough samples, the MCMC chain samples $\Theta$ at the proportion of the true posterior density.  The resulting simulated values can then be used for statistical inference.  Much more can be said regarding MH.  Interested readers can refer to the following references ... (list references here)

## Limitations of Metropolis-Hastings

The theoretical requirements for fitting models using MH are minimal, making MH an attractive choice for Bayesian inference even today.  The limits of MH are primarily computational in nature.  Since the proposals of $\Theta$ are randomly selected, many simulations are required to accurately describe the true posterior.  Even efficient MH implementations may accept less than 25\% of the proposals (cite Gelman).  

The limited efficiency of MH can be overcome by high computational power for certain applications.  When the dimensionality of the data is small to moderate, a well-programmed MH algorithm can sample enough points from the posterior density in a reasonable period of time.  The challenge of relying on MH occurs when dealing with high-dimensional data or complex statistical models.  In these situations, MH is known to be inefficient (reference here) and can be impractical for such applications.  

A popular, often efficient alternative to MH is Gibbs Sampling (footnote that Gibbs is a particular case of MH?).  Gibbs is widely used in many Bayesian software platforms such as WinBUGS and JAGS.  When the conditional posterior densities can be explicitly formulated, Gibbs remains a viable choice for the Bayesian practitioner.  Such restrictions limit the application of Gibbs to particular combinations of models and priors.  Gibbs therefore lacks the flexibility of MH, in addition to having certain other efficiency limitations of its own (cite Robert).  

Given the modern computational demands of large dataset and complex models, a more efficient MCMC algorithm is desirable.  Ideally, such an algorithm would retain the theoretical advantages and flexibility of MH, while providing a more computational efficient method of selecting proposals.  Here we transition to the modern HMC algorithm, and why HMC has emerged as a standard inferential tool for many Bayesian practitioners.  

# HMC Background

MH and HMC are equally flexible in their theoretical capabilities to fit a variety of model and prior specifications.  The key advantage of HMC over MH is the use of additional information from the posterior to guide proposals.  HMC uses the gradient of the log posterior to direct the Markov chain to the region the region of highest posterior density, where most of the samples should occur.  In contrast, MH relies entirely on the acceptance ratio to guide the chain.   As a result, a well-tuned HMC chain will accept proposals approximately 3 times the frequency of a similarly well-tuned MH algorithm (footnote?:  based on MH theoretical optimal acceptance rate of 0.234 and HMC acceptance of 0.6-0.9).   

It should be noted that HMC is a MCMC simulation method, not an optimization method.  While the HMC algorithm guides proposals to regions of high density (sometimes called the typical set  Betancourt), the tails of the density are properly sampled as well.  Both MH and HMC produce ergodic Markov chains, but the mathematics of HMC is substantially more complex than MH.  We provide a brief overview of the theoretical basis of HMC here, and refer to other sources for more detailed expositions (refer to Wiley paper, Betancourt).

## Hamiltonian Monte Carlo Concepts and Theory

As with MH, our objective in HMC is to simulate the posterior $p(\Theta | \pmb{X})$.  The mathematical basis of HMC is the Hamiltonian function

$$
\begin{aligned}
H(\pmb{p}, \Theta) &= K(\pmb{p}, \Theta) + U(\Theta) \\
&= -\log p(\pmb{p}) - \log p(\Theta).
\end{aligned}
$$

HMC introduces a latent parameter $\pmb{p} = (p_1, ..., p_k)$ of the same length $k$ as the parameter of interest $\Theta = (\theta_1, ..., \theta_k )$.  The latent parameter $\pmb{p}$ is often called the \textit{momentum} based on its original application to physical laws of motion.  The incorporation of the momentum provides the geometrical structure of the space through which the Markov chain travels.  The purpose of the momentum is to ensure that the MCMC simulation is ergodic, covering the entire space of $\Theta$.  

The distribution of $\pmb{p}$ is most often specified to be multivariate Normal with covariance $M$.  The structure of $M$ is often diagonal, but does not have to be.  

$$
\begin{aligned}
\pmb{p} &\sim N_k(0, M) \\
\log p(\pmb{p}) &\propto \frac{1}{2}\pmb{p}^T M^{-1}\pmb{p}
\end{aligned}
$$

The Hamiltonian function represents the joint distribution of the multivariate Normal $\pmb{p}$ and the log posterior $p(\Theta | \pmb{X})$, whose notation we simplify to $p(\Theta)$.

$$
\begin{aligned}
H(\pmb{p}, \Theta) &= -\frac{1}{2}\pmb{p}^T M^{-1} \pmb{p} - \log p(\Theta)
\end{aligned}
$$
The trajectories over which HMC travels in time are defined by first-order differential equations, 

$$
\begin{aligned}
\frac{d\pmb{p}}{dt} &= -\frac{\partial H(\Theta, \pmb{p})}{\partial\Theta}= -\frac{\partial U(\Theta)}{\partial\Theta} = \nabla_\Theta \log p(\Theta) \\
\frac{d\Theta}{dt} &= \frac{\partial H(\Theta, \pmb{p})}{\partial\pmb{p}} = \frac{\partial K(\pmb{p})}{\partial\pmb{p}} = M^{-1}\pmb{p}
\end{aligned}
$$
Here we see the explicit formulation of the gradient of the log posterior $\nabla_\Theta \log p(\Theta)$.  The combination of these two equations forms deterministic paths for the MCMC chain to travel through the joint distribution $(\pmb{p}, \Theta)$.  Note that while the MCMC produces simulations of both $\pmb{p}$ and $\Theta$, only the values of $\Theta$ are of interest for statistical inference.  

A solution for these differential equations is necessary to produce a practical MCMC simulation.  Since no exact solution exists, a discrete approximation is needed to form the algorithm.  The most commonly used solution is called the leapfrog method.  The leapfrog defines a discrete step size $\epsilon$ individually for $\pmb{p}$ and $\Theta$.  

$$
\begin{aligned}
\pmb{p}(t + \epsilon/2) &= \pmb{p}(t) + (\epsilon/2)\nabla_\Theta\log\pi(\Theta(t)) \\
\Theta(t + \epsilon) &= \Theta(t) + \epsilon M^{-1}\pmb{p}(t + \epsilon/2) \\
\pmb{p}(t + \epsilon) &= \pmb{p}(t + \epsilon/2) + (\epsilon/2)\nabla_\Theta \log\pi(\Theta(t + \epsilon)).
\end{aligned}
$$

The full step $\epsilon$ in $\Theta$ is sandwiched by half-steps $\epsilon/2$ for $\pmb{p}$. The number of steps $\epsilon$ in an actual HMC algorithm is typically defined by a tuning parameter $L > 1$.    This leapfrog approximation, though slightly more complex than Euler approximations, provides a more accurate approximation of the solution over the many samples that HMC requires.  

The paths defined by the Hamiltonian equations are deterministic once $\pmb{p}$ is defined.  An exact solution would always be accepted in a MCMC algorithm.  However, since the solution to the Hamiltonian equations is an approximation, a Metropolis-Hastings style acceptance ratio is used to formally determine whether a proposal is accepted or rejected.

With the overview of the major concepts in HMC complete, we turn to the formulation of the Hamiltonian Monte Carlo algorithm itself.  

## Hamiltonian Monte Carlo Algorithm

The HMC algorithm is presented in full here.  

\begin{algorithm}
\caption{Euclidean Hamiltonian Monte Carlo}\label{EHMC}
\begin{algorithmic}[1]
\Procedure{EHMC}{$\Theta^{(0)}, \log\pi(\Theta), M, N, \epsilon, L$} 
   \State Calculate $\log\pi(\Theta^{(0)})$ \Comment{Initial value for log posterior}
   \For{$t = 1, ..., N$}\Comment{Repeat simulation $N$ times}
      \State $p^0 \gets N(0, M)$ \Comment{Randomly sample momentum from MVN}
      \State $\Theta^{(t)} \gets \Theta^{(t-1)}, \tilde{\Theta} \gets \Theta^{(t-1)}, \tilde{p} \gets p^{(0)}$ \Comment{Randomly sample from a uniform density, 0 to 1}
      \For{$i = 1, ..., L$}\Comment{Run Leapfrog $L$ times}
        \State $\tilde\Theta, \tilde{p} \gets \text{Leapfrog}(\tilde\Theta, \tilde{p}, \epsilon)$
      \EndFor\label{leapfrogfor}
      \State $\alpha = \min{\left(1, \frac{\exp(\log\tilde\Theta) - \frac{1}{2}\tilde{p}\cdot\tilde{p}}{\exp(\log\tilde\Theta^{(t-1)}) - \frac{1}{2}p^0 \cdot p^0} \right)}$ \Comment{Calculate acceptance proposal probability}
      \State With probability $\alpha$, $\Theta^{(t)}\gets\tilde\Theta$ and $p^{(t)} \gets -\tilde{p}$ 
   \EndFor\label{ehmcendfor}
   \State \textbf{return} $\Theta^{(1)} ... \Theta^{(N)}$ \Comment{Return simulated values of $\Theta$ from the unnormalized posterior}
\Function{Leapfrog}{$\Theta, p, \epsilon$}
\State $\tilde{p} \gets p + (\epsilon/2)\nabla_\Theta\log\pi(\Theta)$
\State $\tilde\Theta \gets \Theta + \epsilon\tilde{p}$
\State $\tilde{p} \gets \tilde{p} + (\epsilon/2)\nabla_\Theta\log\pi(\Theta)$
\State \textbf{return} $\tilde\Theta, \tilde{p}$
\EndFunction
\EndProcedure
\end{algorithmic}
\end{algorithm}

One may notice some similarities with MH:  

\begin{enumerate}
\item An initial set of values $\Theta^{(0)}$ is required for both MH and HMC.
\item The random walk Metropolis proposal is often Multivariate Normal.  HMC simulates from the momentum $\pmb{p}$ from a Multivariate Normal.  
\item Proposals are accepted or rejected based on a ratio of log posteriors in both MH and HMC.  
\end{enumerate}

The key functional difference between the two algorithms is the leapfrog update process.  HMC generates a proposal $(\pmb{p}^t, \Theta^t)$ based on the randomly selected values of $\pmb{p}$ and the number of leapfrog steps $L$.  In contrast, MH selects a proposal from one simple randomly selected value from a proposal distribution.   MH is therefore computationally simpler, but undirected.  HMC's proposal combines the randomization provided by $\pmb{p}$ with trajectories defined the by the gradient of the log posterior $\nabla_\Theta\log\pi(\Theta(t))$. 

From an implementation standpoint, the additional programming required for HMC is fairly minimal.  Manually determiming the gradient may be tedious, but the derivation is typically not difficult.  Once the gradient is provided and coded, programming the leapfrog loop itself is straightforward.  

The challenge of practical HMC implementation is related to implementation of MH - tuning.  While tuning MH involves adjusting a proposal density and little else, HMC requires the selection and adjustment of the mass matrix $M$, number of leapfrog steps $L$, and step size $\epsilon$.  

While $M$ can be fixed as an identity matrix, some modification of the diagonal, at a minimum, can provide notable improvements in computational efficiency.  The selection of $L$ is also an essential step in HMC implementation.  Selecting $L$ too low will produce a Markov chain that is inefficient, and may behave in pattern similar to random walk Metropolis, but with the penalty of additional computation.  Setting $L$ too high can also be inefficient, where the chain may travel through the entire deterministic trajectory multiple times before a proposal is selected.  Finally, $\epsilon$ can be set as a single constant for all $k$ parameters, but varying $\epsilon$ for each individual parameter may improve computational efficiency.  

Developing an intuition and appreciation for how HMC works can be challenging without direct experience working with the algorithm.  The next section provides R code and some simple examples for the interested reader to gain practical, hands-on experience with implementing and tuning HMC.  

# HMC Implementation

We introduce several functions for implementing HMC in the R language.  The function \textit{hmc} runs the main HMC algorithm.  This function calls a separate function for the leapfrog algorithm and random value generation.  Also, the user must specify functions to calculate both the log posterior as well as the gradient of the log posterior.  These functions are used by both the main HMC function as well as the leapfrog function.

## hmc function

First we describe the main \textit{hmc} function itself.  

```{r, echo=TRUE, eval=FALSE}
# Main hmc function
hmc <- function(N, theta.init, epsilon, L, logPOSTERIOR, glogPOSTERIOR, y, X, Z=NULL,
                randlength=FALSE, Mdiag=NULL, verbose=FALSE, ...) {

  p <- length(theta.init) # number of parameters

  # mass matrix
  mu.p <- rep(0, p)

  # epsilon values
  eps_orig <- epsilon
  if (length(epsilon) == 1) {
    eps_orig <- rep(epsilon, p)
  }

  # epsilon matrix
  eps_vals <- matrix(rep(eps_orig, N), ncol=N, byrow=F)

  # number of steps
  nstep_vals <- rep(L, N)

  # randomize epsilon and L
  if (randlength) {
    randvals <- replicate(N, runif(p, -0.1*eps_orig, 0.1*eps_orig), simplify=T)
    eps_vals <- eps_vals + randvals
    nstep_vals <- round(runif(N, 0.5*L, 2.0*L))
  }
  
  # default to unit diagonal matrix
  if (is.null(Mdiag)) {
    M_mx <- diag(p)
  }

  # invert covariance M for leapfrog
  Minv <- qr.solve(M_mx)

  # store theta and momentum (usually not of interest)
  theta <- list()
  theta[[1]] <- theta.init
  r <- list()
  r[[1]] <- NA
  accept <- 0
  for (jj in 2:N) {
    theta[[jj]] <- theta.new <- theta[[jj-1]]
    r0 <- MASS::mvrnorm(1, mu.p, M_mx)
    r.new <- r[[jj]] <- r0
    for (i in 1:L_vals) {
      lstp <- i == L_vals
      lf <- leapfrog(theta_lf = theta.new, r = r.new, epsilon = epsilon, 
                     logPOSTERIOR = logPOSTERIOR,
                     glogPOSTERIOR = glogPOSTERIOR, y = y, X = X, Z = Z,
                     Minv=Minv, constrain=constrain, lastSTEP=lstp, ...)

      theta.new <- lf$theta.new
      r.new <- lf$r.new
    }

    if (verbose) print(jj)

    # standard metropolis-hastings update
    u <- runif(1)

    # use log transform for ratio due to low numbers
    num <- logDENS(theta.new, y=y, X=X, Z=Z, ...) - 0.5*(r.new %*% r.new)
    den <- logDENS(theta[[jj-1]], y=y, X=X, Z=Z, ...) - 0.5*(r0 %*% r0)

    log.alpha <- pmin(0, num - den)

    if (log(u) < log.alpha) {
      theta[[jj]] <- theta.new
      r[[jj]] <- -r.new
      accept <- accept + 1
    } else {
      theta[[jj]] <- theta[[jj-1]]
      r[[jj]] <- r[[jj-1]]
    }

  }
  list(theta=theta,
       r=r,
       accept=accept,
       M=M_mx)
}


```

The arguments of \textit{hmc} are as follows: 

\begin{itemize}
\item N:  Number of MCMC simulations
\item theta.init:  initial values $\Theta^{(0)}$ in vector of length $k$
\item epsilon:  step size $\epsilon$.  Can be a single value or vector length $k$
\item L:  number of leapfrog steps per proposal
\item logPOSTERIOR:  name of function to return the log posterior
\item glogPOSTERIOR:  name of function to return the gradient of the log posterior
\item y:  vector of the dependent variable
\item X:  design matrix of independent variables
\item randlength:  logical to choose whether to randomly vary number of leapfrog steps $L$
\item Mdiag:  optional vector for the diagonal matrix $M$
\item verbose:  logical to print step in the MCMC chain
\item ...:  additional parameters for logPOSTERIOR and glogPOSTERIOR
\end{itemize}

Next, we review the functionality of the \textit{hmc} line-by-line.  

HMC assigns a single latent parameter $p_i$ for each parameter $\theta_i \; \forall i \in 1:k$.  Therefore, \textit{p} is assigned the number of parameters in $\Theta$.   

```{r, echo=TRUE, eval=FALSE}
  p <- length(theta.init)
```

The distribution of the latent variables $\pmb{p}$ is multivariate Normal with mean 0.  The mean of $\pmb{p}$ is assigned a vector 0 for each $p_i$.    

```{r, echo=TRUE, eval=FALSE}
  mu.p <- rep(0, p)
```

In this implementation, $\epsilon$ may be specified as a single number or a vector.  If $\epsilon$ is a single number, it is converted to a vector with a length of the number of parameters.  

The vector is then transated to a matrix repeating the same $\epsilon$ vector for each column of the matrix.  This is used to accommodate some randomness in step size.

```{r, echo=TRUE, eval=FALSE}
  # epsilon values
  eps_orig <- epsilon
  if (length(epsilon) == 1) {
    eps_orig <- rep(epsilon, p)
  }

  # epsilon matrix
  eps_vals <- matrix(rep(eps_orig, N), ncol=N, byrow=F)
```

The number of steps $L$ can also be randomized.  In preparation for this random assignment, the step sizes for each iteration $1...N$ are stored in a vector \textit{L_vals}.

```{r, echo=TRUE, eval=FALSE}
  # number of steps
  L_vals <- rep(L, N)

```

The \textit{randlength} is an optional parameter to randomize $\epsilon$ and $L$.  If this is set to \textit{TRUE}, then a random uniform distribution is used to add some randomness to $\epsilon$.  The number of steps $L$ is similarly randomized, but restricted to integer values.  

```{r, echo=TRUE, eval=FALSE}
  # randomize epsilon and L
  if (randlength) {
    randvals <- replicate(N, runif(p, -0.1*eps_orig, 0.1*eps_orig), simplify=T)
    eps_vals <- eps_vals + randvals
    L_vals <- round(runif(N, 0.5*L, 2.0*L))
  }
```

If the Mass matrix is not provided, the identity matrix is used as a default. 

```{r, echo=TRUE, eval=FALSE}
  # default to unit diagonal matrix
  if (is.null(Mdiag)) {
    M_mx <- diag(p)
  }
```


In preparation for the leapfrog algorithm, the Mass matrix is inverted.

```{r, echo=TRUE, eval=FALSE}
  # invert covariance M for leapfrog
  Minv <- qr.solve(M_mx)
```

Recall that our objective is to simulate values of $\Theta$ from the posterior.  In this function, the simulated values will be stored in a list \textit{theta}.  The first element of the list \textit{theta[[1]]} is assigned to the initial value provided in the function.  

```{r, echo=TRUE, eval=FALSE}
  theta <- list()
  theta[[1]] <- theta.init
```

A second list is created to store simulated values of the momentum $\pmb{p}$.  These simulated values are typically not of interest in analysis, but can be useful in debugging.  The first value of $\pmb{p}$ is assigned \textit{NA} for the initial value of $\Theta$ only.

```{r, echo=TRUE, eval=FALSE}
  r <- list()
  r[[1]] <- NA
```

The acceptance rate of HMC (and MH) is an important measure in assessing the efficiency of the MCMC simulation.  An internal variable \textit{accept} is initialized to zero and is used to count the number of accepted proposals.  

```{r, echo=TRUE, eval=FALSE}
  accept <- 0
```

With the initialization complete, we begin the loop to perform the HMC simulations.  The loop starts at 2 since 1 is reserved for the initial value $\Theta^{(0)}$. 

```{r, echo=TRUE, eval=FALSE}
  for (jj in 2:N) {
```

The default proposed value of $\Theta^{(t)}$ is the previous value in the chain, $\Theta^{(t-1)}$.  This value may be replaced with the proposal depending on the acceptance ratio calculation later in the loop.  

```{r, echo=TRUE, eval=FALSE}
    theta[[jj]] <- theta.new <- theta[[jj-1]]
```

Each proposal requires a simulated value of $\pmb{p}$.  The standard \textit{mapply} function passes the mean vector \textit{mu.p} and standard deviation vector \textit{Mdiag} to the \textit{rnorm} function.  The additional argument \textit{n = 1} is passed to \textit{rnorm} to simulate one value of $p_i$ for each combination of mean and standard deviation in the corresponding vectors.  

The \textit{mvrnorm} function in the \textit{MASS} package is used to simulate a multivariate Normal with mean \textit{mu.p} and covariance matrix \textit{M_mx}

```{r, echo=TRUE, eval=FALSE}
  r0 <- MASS::mvrnorm(1, mu.p, M_mx)
```

The initial sampled value of $p_t$ is stored in the momentum list \textit{r[[m]]}.  This value will be replaced if the proposal is accepted later in the loop.

```{r, echo=TRUE, eval=FALSE}
    r.new <- r[[jj]] <- r0
```

With the previous value $\Theta^{(t-1)}$ and simulated momentum, the leapfrog can be evaluted $L$ consecutive times.  The proposal will be the joint value of $(\pmb{\tilde{p}}^{t}, \tilde\Theta^{(t)})$ after progressing through the $L$ leapfrog steps.  

The simulated values for each leapfrog step are stored in \textit{theta.new} and \textit{r.new}.  After $L$ steps, these variables store the proposal. 

```{r, echo=TRUE, eval=FALSE}
    for (i in 1:L) {
      lstp <- i == Nstep
      lf <- leapfrog(theta_lf = theta.new, r = r.new, epsilon = epsilon, 
                     logPOSTERIOR = logPOSTERIOR,
                     glogPOSTERIOR = glogPOSTERIOR, y = y, X = X, Z = Z,
                     Minv=Minv, constrain=constrain, lastSTEP=lstp, ...)

      theta.new <- lf$theta.new
      r.new <- lf$r.new
    }
```

Next is an optional counter to print the count in the \textit{for} loop.

```{r, echo=TRUE, eval=FALSE}
    if (verbose) print(jj)
```

The proposal is then evaluated in a Metropolis-Hastings style acceptance step.  First, a standard uniform random value is simulated and stored in \textit{u}.  The proposal will be accepted if the acceptance ratio is less than this value.

```{r, echo=TRUE, eval=FALSE}
    u <- runif(1)
```

A log transformation is used to calculate the acceptance ratio.  This transformation is used for numerical stability, since the simulated values of the log posterior can be very high. The log ratio is set to a maximum of 0 since $\log(1) = 0$ is the maximum value in the range $u \in [0, 1]$.  

```{r, echo=TRUE, eval=FALSE}
    num <- logPOSTERIOR(theta.new, y=y, X=X, Z=Z, ...) - 0.5*(r.new %*% r.new)
    den <- logPOSTERIOR(theta[[jj-1]], y=y, X=X, Z=Z, ...) - 0.5*(r0 %*% r0)

    log.alpha <- pmin(0, num - den)
```

Finally, a check is performed on the acceptance ratio.  If $\alpha < u$ (or $\log\alpha < \log u$), then the proposal is accepted.  Otherwise, the previous value in the MCMC chain is retained.

If the proposal is accepted, the negative value of momentum is stored in \textit{r[[m]]}.  This is a technicality to assure that the MCMC chain follows detailed balance (cite here), but this value is not used for inference.  Also, the \textit{accept} variable is incremented by one when the proposal is accepted.  

```{r, echo=TRUE, eval=FALSE}
    if (log(u) < log.alpha) {
      theta[[jj]] <- theta.new
      r[[jj]] <- -r.new
      accept <- accept + 1
    } else {
      theta[[jj]] <- theta[[jj-1]]
      r[[jj]] <- r[[jj-1]]
    }
```

After \textit{N} simulations, a list of results is exported from \textit{hmc}:  

\begin{enumerate}
\item theta:  list of simulated values of $\Theta$
\item r:  list of simulated values of the momentum $\pmb{p}$
\item accept:  the number of accepted proposals in \textit{N} simulations
\item M\_mx:  Mass matrix
\end{enumerate}

```{r, echo=TRUE, eval=FALSE}
  list(theta=theta,
       r=r,
       accept=accept,
       M=M_mx)
```

## Leapfrog function

Next, we review the leapfrog function in more detail. 

```{r, echo=TRUE, eval=FALSE}
leapfrog <- function(theta_lf, r, epsilon, logPOSTERIOR, glogPOSTERIOR, y, X, Z, 
                     Minv, constrain, lastSTEP=FALSE, ...) {
  
  # gradient of log posterior for old theta
  g.ld <- glogPOSTERIOR(theta_lf, y=y, X=X, Z=Z, ...)
  
  # first momentum update
  r.new <- r + epsilon/2*g.ld
  
  # theta update
  # note diagonal matrix update
  # theta.new <- theta_lf + as.numeric(epsilon*r.new/ diag(M_mx))
  theta.new <- theta_lf + as.numeric(epsilon* Minv %*% r.new)
  
  # check positive
  switch_sign <- constrain & theta.new < 0
  r.new[switch_sign] <- -r.new[switch_sign]
  theta.new[switch_sign] <- -theta.new[switch_sign]
  
  # gradient of log posterior for new theta
  g.ld.new <- glogPOSTERIOR(theta.new, y=y, X=X, Z=Z, ...)
  
  # if not on last step, second momentum update
  if (!lastSTEP) {
    r.new <- r.new + epsilon/2*g.ld.new
  }
  list(theta.new=theta.new, 
       r.new=as.numeric(r.new))
}

```

The arguments of \textit{leapfrog} are as follows: 

\begin{itemize}
\item theta\_lf:  Starting position of $\Theta^{(t)}$
\item r:  Starting momentum $p$
\item epsilon:  step size $\epsilon$.  Can be a single value or vector length $k$
\item logPOSTERIOR:  name of function to return the log posterior
\item glogPOSTERIOR:  name of function to return the gradient of the log posterior
\item y:  vector of the dependent variable
\item X:  design matrix of independent variables
\item Z:  optional design matrix for random effects
\item constrain:  logical indicator of whether the support of $\Theta$ is positive only (TRUE) or all real numbers (FALSE)
\item lastSTEP: logical indicator of whether this is the last step of the leapfrog loop.  If it is, then the last half step evaluation for the momentum is not evaluated.
\item ...:  additional parameters for logPOSTERIOR and glogPOSTERIOR
\end{itemize}

Next, we review the functionality of the \textit{leapfrog} line-by-line.  

First, the gradient of the log posterior is evaluated at the initial value provided for $\Theta^{(t)}$.  If \textit{Z} is not provided, a NULL value will be passed to this parameter.  Hyperparameters are passed to the \textit{glogPOSTERIOR} function via \textit{...}.

```{r, echo=TRUE, eval=FALSE}
  # gradient of log posterior for old theta
  g.ld <- glogPOSTERIOR(theta_lf, y=y, X=X, Z=Z, ...)
```

Once the gradient is calculated, the first update of the momentum is performed.  The step size for this first update is half of the step size $\epsilon$.

```{r, echo=TRUE, eval=FALSE}
  # first momentum update
  r.new <- r + epsilon/2*g.ld
```

After the momentum half-step update, $\Theta$ is updated by the full step size $\epsilon$.  

```{r, echo=TRUE, eval=FALSE}
  # theta update
  theta.new <- theta_lf + as.numeric(epsilon* Minv %*% r.new)
```

The next few steps are optionally performed to change the sign of the momentum and $\Theta$ if the support of $\Theta$ is strictly positive (cite Neil).  These steps are only relevant if \textit{constrain} is set to TRUE.  Otherwise, the momentum and $\Theta$ are unchanged.

```{r, echo=TRUE, eval=FALSE}
  # check positive
  switch_sign <- constrain & theta.new < 0
  r.new[switch_sign] <- -r.new[switch_sign]
  theta.new[switch_sign] <- -theta.new[switch_sign]
```

Once $\Theta$ is updated, the gradient of the log posterior is re-calculated at the new set of values.

```{r, echo=TRUE, eval=FALSE}
  # gradient of log posterior for new theta
  g.ld.new <- glogPOSTERIOR(theta.new, y=y, X=X, Z=Z, ...)
```

Finally, unless this the final leapfrog step, the momentum is updated by its second half-step.  

```{r, echo=TRUE, eval=FALSE}
  # if not on last step, second momentum update
  if (!lastSTEP) {
    r.new <- r.new + epsilon/2*g.ld.new
  }
```

The \textit{leapfrog} function then returns the new values of $\Theta$ and momentum in a list.  

```{r, echo=TRUE, eval=FALSE}
  list(theta.new=theta.new,
       r.new=as.numeric(r.new))
```

## Simple example

To illustrate the functionality of the HMC software, we begin with a simple example fitting a Gamma distribution with two parameters $\alpha$ and $\beta$.  The pdf is specified

$$
f(x) = \frac{1}{\beta^\alpha \Gamma(\alpha)} x^{\alpha-1}e^{-x/\beta}I_x(0, \infty)
$$

with likelihood and log likelihood

$$
\begin{aligned}
L(\alpha, \beta; x) &= \prod_{i=1}^n \frac{1}{\beta^\alpha \Gamma(\alpha)} x_i^{\alpha-1}e^{-x_i/\beta} \\
l(\alpha, \beta;x) &= \sum_{i=1}^n -\alpha\log\beta -\log\Gamma(\alpha) + (\alpha-1)\log x_i - x_i/\beta \\
&= -n\alpha\log\beta -n\log\Gamma(\alpha) + (\alpha-1)\sum_{i=1}^n\log x_i - \frac{1}{\beta}\sum_{i=1}^n x_i.
\end{aligned}
$$

Now that the log likelihood has been specified, we can specify our priors.  Both parameters $\alpha$ and $\beta$ are strictly positive.  As such, we can specify half-Normal priors for each of the parameters, with hyperpriors $\eta_1$ and $\eta_2$.

$$
\begin{aligned}
p(\alpha|\eta_1) &= \frac{2\eta_1}{\pi}\exp\left(-\frac{\alpha^2\eta_1^2}{\pi} \right) \\
p(\beta|\eta_2) &= \frac{2\eta_2}{\pi}\exp\left(-\frac{\beta^2\eta_2^2}{\pi} \right)
\end{aligned}
$$

The log posterior is the sum of the log likelihood and the log prior.   

$$
\begin{aligned}
\log p(\alpha, \beta|x) &\propto l(\alpha, \beta; x) + \log p(\alpha,\beta) \\
&\propto  -n\alpha\log\beta -n\log\Gamma(\alpha) + (\alpha-1)\sum_{i=1}^n\log x_i - \frac{1}{\beta}\sum_{i=1}^n x_i - \frac{\alpha^2\eta_1^2}{\pi} - \frac{\beta^2\eta_2^2}{\pi} 
\end{aligned}
$$

Note that we disregard any terms that are not dependent on our parameters of interest $\alpha$ and $\beta$.  These terms are absorbed into the normalizing constant and do not impact the gradient calculation.  

The R functions for the log likelihood and log posterior are provided here.  For our application, our parameter of interest is defined $\Theta := (\alpha, \beta)$.  

```{r, echo=TRUE, eval=TRUE}
# log likelihood of gamma
llgamma <- function(theta, X, y=NULL, Z=NULL) {
  alpha <- theta[1]
  beta <- theta[2]
  n <- length(X)
  -n*alpha*log(beta) - n*log(gamma(alpha)) + (alpha-1)*sum(log(X)) - sum(X)/beta
}

# log posterior of gamma
gamma.lposterior <- function(theta, X, eta1, eta2, y=NULL, Z=NULL) {
  alpha <- theta[1]
  beta <- theta[2]
  llgamma(theta, X) - beta^2 * eta1^2/pi - alpha^2 * eta2^2/pi
}
```


Since our model has two parameters, the partial derivatives must be calculated with respect to $\alpha$ and $\beta$.  

$$
\begin{aligned}
\nabla_\alpha \log p(\alpha, \beta|x) &= -n\log\beta -n\psi(\alpha) + \sum_{i=1}^n\log x_i -2\alpha\eta_1^2/\pi \\
\nabla_\beta \log p(\alpha, \beta|x) &= -\frac{n\alpha}{\beta} + \frac{1}{\beta^2}\sum_{i=1}^n x_i - 2\beta\eta_2^2/\pi
\end{aligned}
$$

The R function for the gradient of the log posterior is provided here.

```{r, echo=TRUE, eval=TRUE}
# derivative of posterior
g.gamma.lposterior <- function(theta, X, eta1, eta2) {
  alpha <- theta[1]
  beta <- theta[2]
  n <- length(X)
  dalpha <- -n*log(beta) -n*digamma(alpha) + sum(log(X)) - 2*alpha*eta1^2/pi
  dbeta <- -n*alpha/beta + sum(X)/beta/beta - 2*beta*eta2^2/pi
  c(dalpha, dbeta)
}
```

Now that the log posterior and gradient have been derived and coded in R, we can run the \textit{hmc} function to fit the model. 

First, we simulate data based on a gamma distribution.  Here, we simulate 1000 data points with $\alpha = 2$ and $\beta = 3$. 

```{r, echo=TRUE, eval=TRUE}
# simulate data
set.seed(312)
X <- rgamma(1000, 2, 1/3)
```

Next, we run our $\textit{hmc}$ function on our simulated data.

```{r, echo=TRUE, eval=TRUE}
N <- 10000
set.seed(143)
hmc.results <- hmc(N, theta.init = c(3, 4), epsilon = 2e-2, L = 22, 
                   logPOSTERIOR = gamma.lposterior, 
                   glogPOSTERIOR = g.gamma.lposterior, X=X, 
                   eta1 = 1e-4, eta2 = 1e-4)
```



