<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>hmclearn package:  Linear Mixed Effects Regression Example • hmclearn</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/sandstone/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="hmclearn package:  Linear Mixed Effects Regression Example">
<meta property="og:description" content="hmclearn">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">hmclearn</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/linear_mixed_effects_hmclearn.html">hmclearn package:  Linear Mixed Effects Regression Example</a>
    </li>
    <li>
      <a href="../articles/linear_regression_hmclearn.html">hmclearn package:  Linear Regression Example</a>
    </li>
    <li>
      <a href="../articles/logistic_mixed_effects_hmclearn.html">hmclearn package:  Logistic Mixed Effects Regression Example</a>
    </li>
    <li>
      <a href="../articles/logistic_regression_hmclearn.html">hmclearn:  Logistic Regression Example</a>
    </li>
    <li>
      <a href="../articles/poisson_regression_hmclearn.html">hmclearn:  Poisson Regression Example</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>hmclearn package: Linear Mixed Effects Regression Example</h1>
                        <h4 class="author">Samuel Thomas</h4>
            
            <h4 class="date">2020-05-30</h4>
      
      
      <div class="hidden name"><code>linear_mixed_effects_hmclearn.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>This vignette demonstrates fitting a Linear mixed effects regression model via Hamiltonian Monte Carlo (HMC) using the <strong>hmclearn</strong> package,</p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">hmclearn</span>)</pre></body></html></div>
</div>
<div id="linear-mixed-effects-model" class="section level2">
<h2 class="hasAnchor">
<a href="#linear-mixed-effects-model" class="anchor"></a>Linear Mixed Effects Model</h2>
<p>We specify the model and prior distributions for <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\boldsymbol\epsilon\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{y} &amp;= \mathbf{X}\boldsymbol\beta + \mathbf{Z}\mathbf{u} + \boldsymbol\epsilon, \\
\mathbf{u} &amp;\sim N(0, \mathbf{G}),  \\
\boldsymbol\epsilon &amp;\sim N(0, \sigma_\epsilon^2).
\end{aligned}
\]</span></p>
<p>The response for each subject is a vector <span class="math inline">\(\mathbf{y} = (\mathbf{y}_1, ..., \mathbf{y}_n)\)</span> for <span class="math inline">\(n\)</span> subjects <span class="math inline">\(i= 1, ..., n\)</span>. Each subject has <span class="math inline">\(d\)</span> observations <span class="math inline">\(\mathbf{y}_i = (y_{i1}, ..., y_{id})\)</span> and we let <span class="math inline">\(j = 1, ..., d\)</span>. The fixed effect design matrix is composed of matrices for each subject, <span class="math inline">\(\mathbf{X} = (\mathbf{X}_1, ..., \mathbf{X}_n)\)</span>, and <span class="math inline">\(\mathbf{X}_i \in \mathbb{R}^{d\times (q+1)}\)</span> for the fixed effects parameters <span class="math inline">\(\boldsymbol\beta = (\beta_0, ..., \beta_q)\)</span>. The full fixed effects design matrix is therefore <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{nd \times (q+1)}\)</span>.</p>
<p>For random effects, <span class="math inline">\(\mathbf{Z} = \text{diag}(\mathbf{Z}_1, ..., \mathbf{Z}_n)\)</span>, with individual random effects matrices <span class="math inline">\(\mathbf{Z}_i\)</span> for each of the <span class="math inline">\(i\)</span> subjects. A random intercept model specifies <span class="math inline">\(\mathbf{Z}_i\)</span> as a column vector of ones where <span class="math inline">\(\mathbf{Z}_i = \mathbf{z}_i = \mathbf{1}_d\)</span>. The full random effects design matrix <span class="math inline">\(\mathbf{Z} \in \mathbb{R}^{nd\times n}\)</span>. The parameterization for random effects is <span class="math inline">\(\mathbf{u} = (\mathbf{u}_1, ..., \mathbf{u}_n)^T\)</span> with vectors <span class="math inline">\(\mathbf{u}_i\)</span> for each subject. A random intercept model is somewhat simplified where <span class="math inline">\(\mathbf{u}_i = u_i\)</span> denotes a single random intercept parameter for each subject <span class="math inline">\(i\)</span>, and <span class="math inline">\(\mathbf{u} = (u_1, ..., u_n)^T\)</span>.</p>
<p>We set <span class="math inline">\(\mathbf{u}\)</span> as one of our priors, following a multivariate normal distribution, <span class="math inline">\(\mathbf{u} \sim N(0, \mathbf{G})\)</span>. For our random intercept model, the specification of the covariance matrix <span class="math inline">\(\mathbf{G}\)</span> is expanded to facilitate efficient sampling using HMC. We let <span class="math inline">\(\mathbf{u} = \mathbf{G}^{1/2}\boldsymbol\tau\)</span> where <span class="math inline">\(\mathbf{G}^{1/2} = \lambda \mathbf{I}_n\)</span>. An additional parameter <span class="math inline">\(\boldsymbol\tau = (\tau_1, ..., \tau_n)^T\)</span> where each of these parameters is standard normal <span class="math inline">\(\tau_i \sim N(0, 1)\)</span>. The full covariance matrix is then <span class="math inline">\(\mathbf{G} = \lambda^2 \mathbf{I}_n \boldsymbol\tau\)</span>.</p>
<p>The error for each subject <span class="math inline">\(i\)</span> is <span class="math inline">\(\boldsymbol\epsilon_i \sim N(0, \sigma_{\epsilon}^2 \mathbf{I}_d)\)</span>. Since the error distribution is constant for each observations,</p>
<p><span class="math display">\[
\boldsymbol\epsilon \sim N(0, \sigma_{\epsilon}^2 \mathbf{I}_{nd}).
\]</span></p>
<p>The parameterization approach for this model uses a strategy recommended by Betancourt, Girolami (2013) to facilitate more efficient sampling in HMC.</p>
<p>Further, we select a half-t family of distributions appropriate for hierarchical models per Gelman (2006). This parameterization is well-behaved around 0, in contrast to inverse gamma, and provides flexibility for informed priors.</p>
<p>We select a parameterization of <span class="math inline">\(\mathbf{G}\)</span> such that the likelihood and its gradient can be derived for HMC. To this end, we uses LDL decomposition of <span class="math inline">\(\mathbf{G}\)</span> to form a flexibile parameterization that can easily handle restrictions (Chan, Jelizkov 2009).</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{u} &amp;\sim N(0, \mathbf{G}),  \\
\mathbf{G} &amp;= \mathbf{L} \mathbf{D} \mathbf{L}^T,  \\
&amp;= \mathbf{L} \mathbf{D}^{1/2} \mathbf{D}^{1/2} \mathbf{L}^T. \\
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(\boldsymbol{\lambda} = (\lambda_1, ..., \lambda_p)\)</span> denote the diagonal elements of <span class="math inline">\(\mathbf{D}^{1/2}\)</span> where <span class="math inline">\(p\)</span> indicates the number of random effect parameters, specified as <em>nrandom</em> in <strong>hmclearn</strong>. A future release of <strong>hmclearn</strong> will allow prior specification for the off-diagonal elements of <span class="math inline">\(L\)</span>. For the current version, we let <span class="math inline">\(L = I_{p}\)</span>.</p>
<p><span class="math display">\[
\mathbf{D}^{1/2} := 
\begin{pmatrix}
\lambda_1 &amp; 0 &amp; ... &amp; 0 \\
0 &amp; \lambda_2 &amp; 0 ... &amp; 0 \\
... &amp; ... &amp; ... &amp; ... \\
0 &amp; 0 &amp; ... &amp; \lambda_p
\end{pmatrix}, \quad
\mathbf{L} :=
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; ... &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; ... &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; ... &amp; ... \\
... &amp; ... &amp; ... &amp; ... &amp; ... \\
0 &amp; 0 &amp; ... &amp; ... &amp; 1 \\
\end{pmatrix}.
\]</span></p>
<p>Consider priors where <span class="math inline">\(jj = 1...p\)</span>. The priors for <span class="math inline">\(\boldsymbol\lambda = (\lambda_1, \lambda_p)^T\)</span> is half-t per Gelman (2006).</p>
<p><span class="math display">\[
\begin{aligned}
\pi(\boldsymbol\beta | \sigma_\beta^2) &amp;\propto N(0, \sigma_\beta^2 \mathbf{I}), \\
\pi(\sigma_\epsilon) &amp;\sim  \left(1 + \frac{1}{\nu_\epsilon}\left(\frac{\sigma_\epsilon}{A_\epsilon} \right)^2 \right)^{-(\nu_\epsilon+1)/2},  \\
\pi(\boldsymbol\lambda) &amp;\sim  \left(1 + \frac{1}{\nu_\lambda}\left(\frac{\boldsymbol\lambda}{A_\lambda} \right)^2 \right)^{-(\nu+1)/2}.
\end{aligned}
\]</span></p>
<p>We want proposals of <span class="math inline">\(\sigma_\epsilon^2\)</span> over the real number line. Therfore we derive the distribution of the transformed parameter <span class="math inline">\(\gamma\)</span> based on a change of variable</p>
<p><span class="math display">\[
\begin{aligned}
\gamma &amp;:= \log \sigma_\epsilon, \\
e^\gamma &amp;= \sigma_\epsilon.
\end{aligned}
\]</span></p>
<p>We need to compute the Jacobian of the transformation</p>
<p><span class="math display">\[
\begin{aligned}
\pi_{\gamma}(\gamma | \nu_\gamma, A_\gamma) &amp;= \pi_{\sigma_\epsilon}(g^{-1}(\gamma))\left\lvert \frac{d\sigma_\epsilon}{d\gamma} \right\rvert, \\
&amp;= \left(1 + \frac{1}{\nu_\gamma} \left(\frac{e^\gamma}{A_\gamma} \right)^2 \right)^{-\frac{\nu_\gamma +1}{2}} e^{\gamma}, \\
&amp;= \left(1 + \frac{1}{\nu_\gamma} \frac{e^{2\gamma}}{A_\gamma^2} \right)^{-\frac{\nu_\gamma +1}{2}} e^{\gamma}, \\
\log \pi(\gamma | \nu_\gamma, A_\gamma) &amp;\propto -\frac{\nu_\gamma+1}{2}\log\left(1 + \frac{1}{\nu_\gamma} \frac{e^{2\gamma}}{A_\gamma^2} \right) + \gamma.
\end{aligned}
\]</span></p>
<p>We want proposals of <span class="math inline">\(\boldsymbol\lambda\)</span> over the real number line. Therfore we derive the distribution of the transformed parameter <span class="math inline">\(\boldsymbol\xi\)</span> based on a change of variable</p>
<p><span class="math display">\[
\begin{aligned}
\boldsymbol\xi &amp;:= \log\boldsymbol\lambda,  \\
\boldsymbol\lambda &amp;:= e^{\boldsymbol\xi}. 
\end{aligned}
\]</span></p>
<p>We need to compute the Jacobian of the transformation</p>
<p><span class="math display">\[
\begin{aligned}
\pi_{\boldsymbol\xi}(\boldsymbol\xi) &amp;= \pi_{\boldsymbol\xi}(g^{-1}(\boldsymbol\xi)) \left\lvert \frac{d\boldsymbol\lambda}{d\boldsymbol\xi}  \right\rvert, \\
&amp;= \pi_{\boldsymbol\lambda} (e^{\boldsymbol\xi})\lvert e^{\boldsymbol\xi}\rvert, \\
&amp;= \left(1 + \frac{1}{\nu_\xi} \frac{e^{2\boldsymbol\xi}}{A_{\xi}^2}\right)^{-\frac{\nu_{\xi}+1}{2}}e^{\boldsymbol\xi}, \\
\log \pi(\boldsymbol\xi) &amp;\propto -\frac{\nu_{\xi}+1}{2}\log\left(1 + \frac{1}{\nu_{\xi}} \frac{e^{2\boldsymbol\xi}}{A_{\xi}^2}\right)+ \boldsymbol\xi.
\end{aligned}
\]</span></p>
</div>
<div id="derive-log-posterior-and-gradient-for-hmc" class="section level2">
<h2 class="hasAnchor">
<a href="#derive-log-posterior-and-gradient-for-hmc" class="anchor"></a>Derive log posterior and gradient for HMC</h2>
<p>First, we specify the likelihood and log-likelihood</p>
<p><span class="math display">\[
\begin{aligned}
f(\mathbf{y} | \boldsymbol\beta, \mathbf{u}, \sigma_\epsilon^2) &amp;\propto (\sigma_\epsilon^2)^{-n/2} e^{-\frac{1}{2\sigma_\epsilon^2}(\mathbf{y} - \mathbf{X}\boldsymbol\beta - \mathbf{Z}\mathbf{u})^T (\mathbf{y} - \mathbf{X}\boldsymbol\beta - \mathbf{Z}\mathbf{u})}, \\
\log f(\mathbf{y} | \boldsymbol\beta, \mathbf{u}, \sigma_\epsilon^2) &amp;\propto -{n}\log(\sigma_\epsilon) -\frac{1}{2\sigma_\epsilon^2}(\mathbf{y} - \mathbf{X}\boldsymbol\beta - \mathbf{Z}\mathbf{u})^T (\mathbf{y} - \mathbf{X}\boldsymbol\beta - \mathbf{Z}\mathbf{u}).
\end{aligned}
\]</span></p>
<p>The posterior is defined for priors on <span class="math inline">\(\boldsymbol\beta\)</span>, <span class="math inline">\(\mathbf{u}\)</span>, <span class="math inline">\(\sigma_\epsilon^2\)</span>, and <span class="math inline">\(\mathbf{G}\)</span>, with dependent vector <span class="math inline">\(\mathbf{y}\)</span> and design matrices <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Z}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
f(\boldsymbol\beta, \mathbf{u}, \sigma_\epsilon^2, \mathbf{G} | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2) &amp;\propto f(\mathbf{y} | \boldsymbol\beta, \mathbf{u}, \sigma_\epsilon^2, \mathbf{G})  \pi(\boldsymbol\beta, \mathbf{u}, \sigma_\epsilon^2, \mathbf{G} | \sigma_\beta^2),  \\
&amp;\propto f(\mathbf{y} | \boldsymbol\beta, \mathbf{u}, \sigma_\epsilon^2, \mathbf{G}) \pi(\boldsymbol\beta | \sigma_\beta^2) \pi(\sigma_\epsilon^2) \pi(\mathbf{u}, \mathbf{G}), \\
&amp;\propto f(\mathbf{y} | \boldsymbol\beta, \mathbf{u}, \sigma_\epsilon^2, \mathbf{G}) \pi(\boldsymbol\beta | \sigma_\beta^2) \pi(\sigma_\epsilon^2) \pi(\mathbf{u} | \mathbf{G}) \pi(\mathbf{G}), \\
\log f(\boldsymbol\beta, \mathbf{u}, \sigma_\epsilon^2, \mathbf{G} | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2) &amp;\propto \log f(\mathbf{y} | \boldsymbol\beta, \mathbf{u}, \sigma_\epsilon^2, G) + \log \pi(\boldsymbol\beta | \sigma_\beta^2) + \log \pi(\sigma_\epsilon^2)+ \log \pi(\mathbf{u}|\mathbf{G}) + \log \pi(\mathbf{G}), \\
\log f(\boldsymbol\beta,\boldsymbol\tau, \gamma, \boldsymbol\xi | y, X, Z, \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\xi) &amp;\propto \log f(\mathbf{y} | \boldsymbol\beta, \boldsymbol\tau, \gamma, \boldsymbol\xi) + \log \pi(\boldsymbol\beta | \sigma_\beta^2) + \log \pi(\gamma | \nu_\gamma, A_\gamma)+ \\
&amp;\qquad\log \pi(\tau) + \log \pi(\boldsymbol\xi | \nu_\xi, A_\xi).
\end{aligned}
\]</span></p>
<p>We write the re-parameterized log likelihood,</p>
<p><span class="math display">\[
\begin{aligned}
\log f(\mathbf{y}|\mathbf{X}, \mathbf{Z}, \boldsymbol\beta, \boldsymbol\tau, \boldsymbol\xi, \gamma) = -nd\log\gamma - \frac{e^{-2\gamma}}{2} (\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau)^T(\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau).
\end{aligned}
\]</span></p>
<p>Next, the log priors that we use with transformations, omitting constants. Note that the log densities of the priors with log densities include an additive term for the transformed distribution (i.e. <span class="math inline">\(\xi\)</span> and <span class="math inline">\(\gamma\)</span>),</p>
<p><span class="math display">\[
\begin{aligned}
\log \pi(\boldsymbol\beta | \sigma_\beta^2) &amp;\propto -\frac{\boldsymbol\beta^T \boldsymbol\beta}{2\sigma_\beta^2}, \\
\log \pi(\boldsymbol\xi | \nu_\xi, A_\xi) &amp;\propto -\frac{\nu_\xi + 1}{2} \log \left( 1 + \frac{1}{\nu_\xi} \left(\frac{e^\boldsymbol\xi}{A_\xi} \right)^2 \right) + \boldsymbol\xi, \\
\log \pi(\boldsymbol\tau) &amp;\propto -\frac{1}{2}\boldsymbol\tau^T \boldsymbol\tau, \\
\log \pi(\gamma | \nu_\gamma, A_\gamma) &amp;\propto -\frac{\nu_\gamma + 1}{2} \log \left( 1 + \frac{1}{\nu_\gamma} \left(\frac{e^\gamma}{A_\gamma} \right)^2 \right) + \gamma.
\end{aligned}
\]</span></p>
<p>The full log posterior with transformed variables is the log likelihood plus the log prior,</p>
<p><span class="math display">\[
\begin{aligned}
\log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\xi) &amp;\propto \log f(\mathbf{y} | \mathbf{X}, \mathbf{Z}, \boldsymbol\beta, \xi, \boldsymbol\tau, \gamma)  + \log \pi(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\gamma), \\ 
&amp;\propto \log f(\mathbf{y} | \mathbf{X}, \mathbf{Z}, \boldsymbol\beta, \xi, \boldsymbol\tau, \gamma) + \log \pi(\boldsymbol\beta | \sigma_\beta^2) + \log \pi(\xi | \nu_\xi, A_\xi) + \\
&amp;\qquad \log\pi(\boldsymbol\tau) + \log\pi(\gamma | \nu_\gamma, A_\gamma),  \\
&amp;\propto -nd\gamma - \frac{1}{2 e^{2\gamma}} (\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau)^T(\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau) - \\
&amp;\quad \frac{\boldsymbol\beta^T \boldsymbol\beta}{2\sigma_\beta^2} -\frac{\nu_\xi + 1}{2} \sum_{jj = 1}^p \log \left( 1 + \frac{1}{\nu_{\xi_{jj}}} \left(\frac{e^{\xi_{jj}}}{A_\xi} \right)^2 \right) + \xi - \\
&amp;\quad \frac{1}{2}\boldsymbol\tau^T \boldsymbol\tau -\frac{\nu_\gamma + 1}{2} \log \left( 1 + \frac{1}{\nu_\gamma} \left(\frac{e^\gamma}{A_\gamma} \right)^2 \right) + \gamma.
\end{aligned}
\]</span></p>
<p>Next we derive the gradient of the log posterior, comprised of partial derivatives for each of our parameters.</p>
<p>We derive the partial derivative of <span class="math inline">\(\boldsymbol\beta\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_\beta \log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\xi) &amp;\propto -\frac{1}{2e^{2\gamma}} (-2) \sum_{\boldsymbol\xi = (\xi_1, ..., \xi_p)} \mathbf{X}^T(y-\mathbf{X}\boldsymbol\beta - e^{\boldsymbol\xi}\mathbf{Z}\boldsymbol\tau)- \frac{1}{\sigma_\beta^2}\boldsymbol\beta, \\
&amp;\propto e^{-2\gamma}\mathbf{X}^T(y-\mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau)- \boldsymbol\beta / \sigma_\beta^2.
\end{aligned}
\]</span></p>
<p>Next we derive the partial derivative of each parameter <span class="math inline">\(\xi_1, ..., \xi_p\)</span> where <span class="math inline">\(jj = 1, ..., p\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_{\xi_{jj} }\log f(\boldsymbol\beta, \boldsymbol\xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\xi) &amp;\propto -\frac{e^{-2\gamma}}{2}(-2)(\mathbf{Z}\boldsymbol\tau)^T e^{\xi_{jj}} (\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi_{jj}}\mathbf{Z}\boldsymbol\tau) - \frac{\nu_\xi + 1}{2}\left( 1 + \frac{1}{\nu_\xi} \left(\frac{e^\xi_{jj}}{A_\xi} \right)^2 \right)^{-1}\frac{2\xi_{jj}}{\nu_\xi A_\xi^2} + 1, \\
&amp;\propto e^{-2\gamma + \xi_{jj}} \boldsymbol\tau^T \mathbf{Z}^T (\mathbf{y}-\mathbf{X}\boldsymbol\beta -e^{\xi_{jj}}\mathbf{Z}\boldsymbol\tau) - \frac{\nu_\xi + 1}{1 + \nu_\xi A_\xi^2 e^{-2\xi_{jj}}} + 1.
\end{aligned}
\]</span></p>
<p>Next, we derive the partial derivative of <span class="math inline">\(\boldsymbol\tau\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_\tau \log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\xi) &amp;\propto -\frac{e^{-2\gamma}}{2}(-2)(\mathbf{Z}\boldsymbol)^T e^{\xi}(\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau) - \frac{1}{2}\boldsymbol\tau, \\
&amp;\propto e^{-2\gamma} \mathbf{Z}^T(\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau) -  \boldsymbol\tau.
\end{aligned}
\]</span></p>
<p>The gradient of full log posterior can now be specified</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_{\boldsymbol\beta} \log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\xi), 
&amp;\propto e^{-2\gamma}\mathbf{X}^T(y-\mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau)-  \boldsymbol\beta / \sigma_\beta^2, \\
\nabla_{\xi_{jj}} \log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\xi) &amp;\propto e^{-2\gamma + \xi_{jj}} \boldsymbol\tau^T \mathbf{Z}^T (\mathbf{y}-\mathbf{X}\boldsymbol\beta -e^{\xi_{jj}}\mathbf{Z}\boldsymbol\tau) - \frac{\nu_\xi + 1}{1 + \nu_\xi A_\xi^2 e^{-2\xi_{jj}}} + 1, \quad \forall (\xi_1, ..., \xi_p) \in \boldsymbol\xi, \\
\nabla_{\boldsymbol\tau} \log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\xi) &amp;\propto e^{-2\gamma} \mathbf{Z}^T(\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau) - \boldsymbol\tau, \\
\nabla_\gamma \log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\gamma, A_\gamma, \nu_\xi, A_\xi) &amp;\propto  -nd + e^{-2\gamma}(\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau)^T (\mathbf{y} - \mathbf{X}\boldsymbol\beta - e^{\xi}\mathbf{Z}\boldsymbol\tau) - \frac{\nu_\gamma + 1}{1 + \nu_\gamma A_\gamma^2 e^{-2\gamma}} + 1.
\end{aligned}
\]</span></p>
<p>Note that a random intercept model only has a single <span class="math inline">\(\xi\)</span> parameter, which simplifies the log posterior and gradient formulations.</p>
</div>
<div id="linear-mixed-effecgts-model-example-data" class="section level2">
<h2 class="hasAnchor">
<a href="#linear-mixed-effecgts-model-example-data" class="anchor"></a>Linear mixed effecgts model example data</h2>
<p>The user must define provide the design matrix directly for use in <strong>hmclearn</strong>. Our first step is to load the data and store the fixed effect design matrix <span class="math inline">\(\mathbf{X}\)</span>, random effects design matrix <span class="math inline">\(\mathbf{Z}\)</span>, and dependent variable vector <span class="math inline">\(\mathbf{y}\)</span>.</p>
<p>We load drug sleepstudy data (Belenky et. al. 2003) and create the design matrices <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Z}\)</span> and dependent vector <span class="math inline">\(\mathbf{y}\)</span>. For this model, the random effects design matrix <span class="math inline">\(\mathbf{Z}\)</span> is specified for a random intercept model.</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">lme4</span>)
<span class="co">#&gt; Loading required package: Matrix</span>
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">Matrix</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="no">sleepstudy</span>)

<span class="co"># dependent variable</span>
<span class="no">y</span> <span class="kw">&lt;-</span> <span class="no">sleepstudy</span>$<span class="no">Reaction</span>

<span class="no">yi.lst</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/split.html">split</a></span>(<span class="no">sleepstudy</span>$<span class="no">Reaction</span>, <span class="no">sleepstudy</span>$<span class="no">Subject</span>)

<span class="co"># fixed effects</span>
<span class="no">ss2</span> <span class="kw">&lt;-</span> <span class="no">sleepstudy</span>
<span class="no">ss2</span>$<span class="no">int</span> <span class="kw">&lt;-</span> <span class="fl">1</span>
<span class="no">ss2</span> <span class="kw">&lt;-</span> <span class="no">ss2</span>[, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">4</span>, <span class="fl">1</span>:<span class="fl">3</span>)] <span class="co"># rearrange columns to store in list</span>
<span class="no">Xi.lst</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/split.html">split</a></span>(<span class="no">ss2</span>[, <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">ss2</span>) <span class="kw">%in%</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Days"</span>, <span class="st">"int"</span>))],
                <span class="no">ss2</span>$<span class="no">Subject</span>)
<span class="no">Xi.lst</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">Xi.lst</span>, <span class="no">as.matrix</span>)

<span class="no">X</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span>(<span class="no">rbind</span>, <span class="no">Xi.lst</span>))

<span class="co"># random effects</span>
<span class="no">n</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span>(<span class="no">sleepstudy</span>$<span class="no">Subject</span>))
<span class="no">d</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">y</span>)/<span class="no">n</span>
<span class="no">nrandom</span> <span class="kw">&lt;-</span> <span class="fl">1</span>

<span class="co">##########</span>
<span class="co"># intercept</span>
<span class="no">Z</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/kronecker.html">kronecker</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span>(<span class="no">n</span>), <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">1</span>, <span class="no">d</span>), <span class="kw">ncol</span><span class="kw">=</span><span class="fl">1</span>))</pre></body></html></div>
</div>
<div id="comparison-model---frequentist" class="section level2">
<h2 class="hasAnchor">
<a href="#comparison-model---frequentist" class="anchor"></a>Comparison model - Frequentist</h2>
<p>To compare results, we first fit a linear mixed effects model using the frequentist package <strong>lme4</strong> (Bates et. al. 2015).</p>
<div class="sourceCode" id="cb3"><html><body><pre class="r"><span class="co"># random intercept </span>

<span class="co">## linear mixed models - reference values from older code</span>
<span class="no">fm1</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span>(<span class="no">Reaction</span> ~ <span class="no">Days</span> + (<span class="fl">1</span> <span class="kw">|</span> <span class="no">Subject</span>), <span class="no">sleepstudy</span>, <span class="kw">REML</span> <span class="kw">=</span> <span class="fl">FALSE</span>)
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">fm1</span>)
<span class="co">#&gt; Linear mixed model fit by maximum likelihood  ['lmerMod']</span>
<span class="co">#&gt; Formula: Reaction ~ Days + (1 | Subject)</span>
<span class="co">#&gt;    Data: sleepstudy</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span>
<span class="co">#&gt;   1802.1   1814.9   -897.0   1794.1      176 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Scaled residuals: </span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -3.2347 -0.5544  0.0155  0.5257  4.2648 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Random effects:</span>
<span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span>
<span class="co">#&gt;  Subject  (Intercept) 1296.9   36.01   </span>
<span class="co">#&gt;  Residual              954.5   30.90   </span>
<span class="co">#&gt; Number of obs: 180, groups:  Subject, 18</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Fixed effects:</span>
<span class="co">#&gt;             Estimate Std. Error t value</span>
<span class="co">#&gt; (Intercept) 251.4051     9.5062   26.45</span>
<span class="co">#&gt; Days         10.4673     0.8017   13.06</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Correlation of Fixed Effects:</span>
<span class="co">#&gt;      (Intr)</span>
<span class="co">#&gt; Days -0.380</span></pre></body></html></div>
</div>
<div id="fit-model-using-hmc" class="section level2">
<h2 class="hasAnchor">
<a href="#fit-model-using-hmc" class="anchor"></a>Fit model using <em>hmc</em>
</h2>
<p>Next, we fit the linear mixed effects regression model using HMC. A vector of <em>tuning parameter</em> <span class="math inline">\(\epsilon\)</span> values are specified to align with the data. The hyperparameters for <span class="math inline">\(\nu_\gamma\)</span>, <span class="math inline">\(A_\gamma\)</span>, <span class="math inline">\(\nu_\xi\)</span>, and <span class="math inline">\(A_\xi\)</span> are set to values more appropriate for hierarchical models (Gelman 2006). The hyperprior <span class="math inline">\(\sigma_\beta^2\)</span> is set higher than the default based on the range of the dependent variable.</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="no">N</span> <span class="kw">&lt;-</span> <span class="fl">2e3</span>

<span class="no">theta.init</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0</span>, <span class="fl">1</span>, <span class="co"># beta </span>
               <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">0</span>, <span class="fl">18</span>), <span class="co"># tau</span>
               <span class="fl">3</span>, <span class="co"># gamma (log sig2eps)</span>
               <span class="fl">1</span>) <span class="co"># xi </span>

<span class="no">vnames</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span>(<span class="st">"beta"</span>, <span class="fl">0</span>:<span class="fl">1</span>),
            <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span>(<span class="st">"tau_int"</span>, <span class="fl">1</span>:<span class="fl">18</span>),
           <span class="st">"sigeps"</span>, <span class="st">"xi"</span>)

<span class="no">eps_vals</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">5e-1</span>, <span class="fl">5e-2</span>,
              <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">3e-2</span>, <span class="fl">18</span>),
              <span class="fl">6e-3</span>,
              <span class="fl">5e-2</span>)

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">41132</span>)
<span class="no">t1.hmc</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html">Sys.time</a></span>()
 <span class="no">f_hmc</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/hmc.html">hmc</a></span>(<span class="kw">N</span> <span class="kw">=</span> <span class="no">N</span>, <span class="kw">theta.init</span> <span class="kw">=</span> <span class="no">theta.init</span>,
               <span class="kw">epsilon</span> <span class="kw">=</span> <span class="no">eps_vals</span>, <span class="kw">L</span> <span class="kw">=</span> <span class="fl">10</span>,
               <span class="kw">logPOSTERIOR</span> <span class="kw">=</span> <span class="no">lmm_posterior</span>,
               <span class="kw">glogPOSTERIOR</span> <span class="kw">=</span> <span class="no">g_lmm_posterior</span>,
               <span class="kw">varnames</span> <span class="kw">=</span> <span class="no">vnames</span>,
               <span class="kw">param</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">y</span>, <span class="kw">X</span><span class="kw">=</span><span class="no">X</span>, <span class="kw">Z</span><span class="kw">=</span><span class="no">Z</span>, <span class="kw">n</span><span class="kw">=</span><span class="no">n</span>, <span class="kw">d</span><span class="kw">=</span><span class="no">d</span>, <span class="kw">nrandom</span><span class="kw">=</span><span class="fl">1</span>,
                          <span class="kw">nugamma</span><span class="kw">=</span><span class="fl">4</span>, <span class="kw">Agamma</span><span class="kw">=</span><span class="fl">1</span>,
                          <span class="kw">nuxi</span><span class="kw">=</span><span class="fl">1</span>, <span class="kw">Axi</span><span class="kw">=</span><span class="fl">1</span>, <span class="kw">sig2beta</span><span class="kw">=</span><span class="fl">1e5</span>),
               <span class="kw">parallel</span><span class="kw">=</span><span class="fl">FALSE</span>, <span class="kw">chains</span><span class="kw">=</span><span class="fl">2</span>)
<span class="no">t2.hmc</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html">Sys.time</a></span>()
<span class="no">t2.hmc</span> - <span class="no">t1.hmc</span>
<span class="co">#&gt; Time difference of 1.283095 mins</span></pre></body></html></div>
<p>The acceptance ratio for each of the HMC chains is sufficiently high for an efficient simulation.</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="no">f_hmc</span>$<span class="no">accept</span>/<span class="no">N</span>
<span class="co">#&gt; [1] 0.814 0.805</span></pre></body></html></div>
<p>Trace plots provide a visual indication of stationarity. These plots indicate that the MCMC chains are reasonably stationary.</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="fu"><a href="../reference/hmclearn-plots.html">mcmc_trace</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">trunc</a></span>(<span class="no">N</span>*<span class="fl">.3</span>), <span class="kw">pars</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"beta0"</span>, <span class="st">"beta1"</span>, <span class="st">"sigeps"</span>, <span class="st">"xi"</span>))</pre></body></html></div>
<p><img src="linear_mixed_effects_hmclearn_files/figure-html/unnamed-chunk-6-1.png" width="576"></p>
<p>The posterior quantiles are summarized after removing an initial <em>burnin</em> period.</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">trunc</a></span>(<span class="no">N</span>*<span class="fl">.3</span>))
<span class="co">#&gt; Summary of MCMC simulation</span>
<span class="co">#&gt;                   2.5%            5%          25%           50%         75%</span>
<span class="co">#&gt; beta0     230.00128348  2.327944e+02 241.89217307 248.352552693 253.7295718</span>
<span class="co">#&gt; beta1       9.07725919  9.328444e+00  10.04105950  10.532795892  11.0469884</span>
<span class="co">#&gt; tau_int1    0.52735664  6.213171e-01   0.93359832   1.167452224   1.4397057</span>
<span class="co">#&gt; tau_int2   -2.99320429 -2.809036e+00  -2.33009109  -2.020047420  -1.7439651</span>
<span class="co">#&gt; tau_int3   -2.51312415 -2.366965e+00  -1.92402317  -1.628754913  -1.3584329</span>
<span class="co">#&gt; tau_int4   -0.45362162 -3.449023e-01  -0.02246452   0.195555766   0.4249330</span>
<span class="co">#&gt; tau_int5   -0.23646113 -1.601095e-01   0.14702177   0.357780409   0.5712771</span>
<span class="co">#&gt; tau_int6   -0.31019917 -2.106870e-01   0.08983899   0.288832127   0.4998416</span>
<span class="co">#&gt; tau_int7   -0.10531375  3.075246e-04   0.32130309   0.521949974   0.7341278</span>
<span class="co">#&gt; tau_int8   -0.63986239 -5.250118e-01  -0.20483523  -0.002182091   0.1992217</span>
<span class="co">#&gt; tau_int9   -1.91743204 -1.799009e+00  -1.41391783  -1.147736157  -0.8954078</span>
<span class="co">#&gt; tau_int10   1.23663902  1.348615e+00   1.73018898   2.013683784   2.3463818</span>
<span class="co">#&gt; tau_int11  -1.16431522 -1.053962e+00  -0.71512168  -0.503604123  -0.2805310</span>
<span class="co">#&gt; tau_int12  -0.18447810 -5.984324e-02   0.24471072   0.463964937   0.6880517</span>
<span class="co">#&gt; tau_int13  -0.79561699 -6.890123e-01  -0.34115241  -0.107625210   0.1020035</span>
<span class="co">#&gt; tau_int14   0.40947078  5.277042e-01   0.82337594   1.045747168   1.2923674</span>
<span class="co">#&gt; tau_int15  -0.36458092 -2.675430e-01   0.05652652   0.263111730   0.5034956</span>
<span class="co">#&gt; tau_int16  -0.74043732 -6.108352e-01  -0.30877607  -0.079167619   0.1401596</span>
<span class="co">#&gt; tau_int17  -0.64757366 -5.363645e-01  -0.23346035  -0.008004814   0.1981716</span>
<span class="co">#&gt; tau_int18  -0.08046339  3.483494e-02   0.35543901   0.554203574   0.7780795</span>
<span class="co">#&gt; sigeps      3.31911275  3.335228e+00   3.38724086   3.420776537   3.4602352</span>
<span class="co">#&gt; xi          3.27813272  3.330004e+00   3.48419242   3.599906725   3.7252319</span>
<span class="co">#&gt;                    95%       97.5%      rhat</span>
<span class="co">#&gt; beta0     263.17481417 266.1468368 1.0001273</span>
<span class="co">#&gt; beta1      11.82741944  12.0676729 1.0152341</span>
<span class="co">#&gt; tau_int1    1.83370042   1.9842790 1.0006277</span>
<span class="co">#&gt; tau_int2   -1.33534270  -1.2014881 1.0136249</span>
<span class="co">#&gt; tau_int3   -0.99843222  -0.8825962 1.0033839</span>
<span class="co">#&gt; tau_int4    0.74445445   0.8650832 1.0040567</span>
<span class="co">#&gt; tau_int5    0.94290556   1.0473653 0.9996973</span>
<span class="co">#&gt; tau_int6    0.86177250   0.9860583 1.0019383</span>
<span class="co">#&gt; tau_int7    1.06812066   1.1716498 1.0004302</span>
<span class="co">#&gt; tau_int8    0.50840065   0.5988963 0.9997383</span>
<span class="co">#&gt; tau_int9   -0.52859063  -0.3619272 1.0020873</span>
<span class="co">#&gt; tau_int10   2.79418829   2.9351339 1.0036116</span>
<span class="co">#&gt; tau_int11   0.03102414   0.1287776 1.0047227</span>
<span class="co">#&gt; tau_int12   1.02133903   1.1617360 0.9996900</span>
<span class="co">#&gt; tau_int13   0.41003730   0.4973619 1.0025572</span>
<span class="co">#&gt; tau_int14   1.67376662   1.8118583 1.0016279</span>
<span class="co">#&gt; tau_int15   0.84116476   0.9484060 0.9998920</span>
<span class="co">#&gt; tau_int16   0.47023929   0.5489269 0.9996697</span>
<span class="co">#&gt; tau_int17   0.50581182   0.6005836 1.0002093</span>
<span class="co">#&gt; tau_int18   1.15456654   1.2893995 1.0051712</span>
<span class="co">#&gt; sigeps      3.51289370   3.5331037 0.9998044</span>
<span class="co">#&gt; xi          3.92390056   3.9952374 1.0162299</span></pre></body></html></div>
<p>Histograms of the posterior distribution show that Bayesian parameter estimates align with frequentist estimates. The <em>cols</em> parameter specifies the parameters to be displayed in <em>diagplots</em>, based on the order provided to the <em>hmc</em> function.</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="no">beta.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/fixef.html">fixef</a></span>(<span class="no">fm1</span>)
<span class="no">xi.freq</span> <span class="kw">&lt;-</span> <span class="fl">1</span>/<span class="fl">2</span>*<span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span>(<span class="fu"><a href="https://rdrr.io/pkg/lme4/man/VarCorr.html">VarCorr</a></span>(<span class="no">fm1</span>)$<span class="no">Subject</span>[<span class="fl">1</span>])
<span class="no">sigeps.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span>(<span class="fu"><a href="https://rdrr.io/pkg/lme4/man/sigma.html">sigma</a></span>(<span class="no">fm1</span>))
<span class="no">theta.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="no">beta.freq</span>, <span class="no">sigeps.freq</span>, <span class="no">xi.freq</span>)

<span class="co"># histograms with lines for frequentist estimates</span>
<span class="fu"><a href="../reference/diagplots.html">diagplots</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">trunc</a></span>(<span class="no">N</span>*<span class="fl">.3</span>),
          <span class="kw">comparison.theta</span><span class="kw">=</span><span class="no">theta.freq</span>, <span class="kw">cols</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">1</span>:<span class="fl">2</span>, <span class="fl">21</span>:<span class="fl">22</span>))
<span class="co">#&gt; $histogram</span></pre></body></html></div>
<p><img src="linear_mixed_effects_hmclearn_files/figure-html/unnamed-chunk-8-1.png" width="768"></p>
<p>We also compare the random effects parameter estimates with <strong>lme4</strong>. The random effects parameters align with</p>
<div class="sourceCode" id="cb9"><html><body><pre class="r"><span class="no">u.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/ranef.html">ranef</a></span>(<span class="no">fm1</span>)$<span class="no">Subject</span>[, <span class="fl">1</span>]
<span class="no">lambda.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="fu"><a href="https://rdrr.io/pkg/lme4/man/VarCorr.html">VarCorr</a></span>(<span class="no">fm1</span>)$<span class="no">Subject</span>[<span class="fl">1</span>])

<span class="co"># transform parameters back to original scale</span>
<span class="no">f_hmc</span>$<span class="no">thetaCombined</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span>, <span class="kw">function</span>(<span class="no">xx</span>) {
  <span class="no">tau_mx</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(<span class="no">xx</span>[, <span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"tau"</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">xx</span>))])
  <span class="no">u_mx</span> <span class="kw">&lt;-</span> <span class="no">tau_mx</span> * <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span>(<span class="no">xx</span>[, <span class="st">"xi"</span>])
  <span class="no">u_df</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span>(<span class="no">u_mx</span>)
  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">u_df</span>) <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span>(<span class="st">"u"</span>, <span class="fl">1</span>:<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span>(<span class="no">u_df</span>))
  <span class="no">xx</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(<span class="no">xx</span>, <span class="no">u_df</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span>(<span class="no">xx</span>[, <span class="st">"xi"</span>]))
  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">xx</span>)[<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span>(<span class="no">xx</span>)] <span class="kw">&lt;-</span> <span class="st">"lambda"</span>
  <span class="no">xx</span>
})

<span class="co"># histograms with lines for frequentist estimates</span>
<span class="no">ucols</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"^u"</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span><span class="kw">[[</span><span class="fl">1</span>]])))
<span class="no">lambdacol</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"^lambda"</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span><span class="kw">[[</span><span class="fl">1</span>]])))
<span class="fu"><a href="../reference/diagplots.html">diagplots</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">trunc</a></span>(<span class="no">N</span>*<span class="fl">.3</span>),
          <span class="kw">comparison.theta</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="no">u.freq</span>, <span class="no">lambda.freq</span>), <span class="kw">cols</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="no">ucols</span>, <span class="no">lambdacol</span>))
<span class="co">#&gt; $histogram</span></pre></body></html></div>
<p><img src="linear_mixed_effects_hmclearn_files/figure-html/unnamed-chunk-9-1.png" width="768"></p>
</div>
<div id="source" class="section level2">
<h2 class="hasAnchor">
<a href="#source" class="anchor"></a>Source</h2>
<p>Gregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. <em>Journal of Sleep Research</em> 12, 1–12.</p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<p>Bates, D., M"{a}chler, M., Bolker, B., &amp; Walker, S. (2015). Fitting linear mixed-effects models using lme4. <em>Journal of Statistical Software</em> 67(1)</p>
<p>Betancourt, M., &amp; Girolami, M. (2015). Hamiltonian Monte Carlo for hierarchical models. <em>Current trends in Bayesian methodology with applications</em>, 79(30), 2-4.</p>
<p>Gelman, Andrew. (2006) “Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper).” <em>Bayesian analysis</em> 1.3: 515-534.</p>
<p>Chan, J. C. C., &amp; Jeliazkov, I. (2009). MCMC estimation of restricted covariance matrices. <em>Journal of Computational and Graphical Statistics</em>, 18(2), 457-480.</p>
<p>Agresti, A. (2015). <em>Foundations of linear and generalized linear models</em>. John Wiley &amp; Sons. ISBN: 978-1-118-73003-4</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Samuel Thomas.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.9000.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
