<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>hmclearn package:  Linear Mixed Effects Regression Example • hmclearn</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/sandstone/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="hmclearn package:  Linear Mixed Effects Regression Example">
<meta property="og:description" content="hmclearn">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">hmclearn</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/linear_mixed_effects_hmclearn.html">hmclearn package:  Linear Mixed Effects Regression Example</a>
    </li>
    <li>
      <a href="../articles/linear_regression_hmclearn.html">hmclearn package:  Linear Regression Example</a>
    </li>
    <li>
      <a href="../articles/logistic_mixed_effects_hmclearn.html">hmclearn package:  Logistic Mixed Effects Regression Example</a>
    </li>
    <li>
      <a href="../articles/logistic_regression_hmclearn.html">hmclearn:  Logistic Regression Example</a>
    </li>
    <li>
      <a href="../articles/poisson_regression_hmclearn.html">hmclearn:  Poisson Regression Example</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>hmclearn package: Linear Mixed Effects Regression Example</h1>
                        <h4 class="author">Samuel Thomas</h4>
            
            <h4 class="date">2020-05-25</h4>
      
      
      <div class="hidden name"><code>linear_mixed_effects_hmclearn.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level1">
<h1 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h1>
<p>This vignette demonstrates fitting a Linear mixed effects regression model via Hamiltonian Monte Carlo (HMC) using the <strong>hmclearn</strong> package.</p>
<p><span class="math display">\[
\begin{aligned}
y &amp;= X\beta + Zu + \epsilon \\
u &amp;\sim N(0, G) \\
\epsilon &amp;\sim N(0, \sigma^2)
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">hmclearn</span>)</pre></body></html></div>
</div>
<div id="linear-mixed-effects-model-example-data" class="section level1">
<h1 class="hasAnchor">
<a href="#linear-mixed-effects-model-example-data" class="anchor"></a>Linear Mixed Effects Model Example Data</h1>
<p>The user must define provide the design matrix directly for use in <strong>hmclearn</strong>. Our first step is to load the data and store the fixed effect design matrix <span class="math inline">\(X\)</span>, random effects design matrix <span class="math inline">\(Z\)</span>, and dependent variable vector <span class="math inline">\(y\)</span>.</p>
<p>We load drug sleepstudy data (Belenky et. al. 2003) and create the design matrices <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span> and dependent vector <span class="math inline">\(y\)</span>. For this model, the random effects design matrix <span class="math inline">\(Z\)</span> is specified for a random intercept model.</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">lme4</span>)
<span class="co">#&gt; Loading required package: Matrix</span>
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">Matrix</span>)
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="no">sleepstudy</span>)

<span class="co"># dependent variable</span>
<span class="no">y</span> <span class="kw">&lt;-</span> <span class="no">sleepstudy</span>$<span class="no">Reaction</span>

<span class="no">yi.lst</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/split.html">split</a></span>(<span class="no">sleepstudy</span>$<span class="no">Reaction</span>, <span class="no">sleepstudy</span>$<span class="no">Subject</span>)

<span class="co"># fixed effects</span>
<span class="no">ss2</span> <span class="kw">&lt;-</span> <span class="no">sleepstudy</span>
<span class="no">ss2</span>$<span class="no">int</span> <span class="kw">&lt;-</span> <span class="fl">1</span>
<span class="no">ss2</span> <span class="kw">&lt;-</span> <span class="no">ss2</span>[, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">4</span>, <span class="fl">1</span>:<span class="fl">3</span>)] <span class="co"># rearrange columns to store in list</span>
<span class="no">Xi.lst</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/split.html">split</a></span>(<span class="no">ss2</span>[, <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">ss2</span>) <span class="kw">%in%</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"Days"</span>, <span class="st">"int"</span>))],
                <span class="no">ss2</span>$<span class="no">Subject</span>)
<span class="no">Xi.lst</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">Xi.lst</span>, <span class="no">as.matrix</span>)

<span class="no">X</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span>(<span class="no">rbind</span>, <span class="no">Xi.lst</span>))

<span class="co"># random effects</span>
<span class="no">n</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/unique.html">unique</a></span>(<span class="no">sleepstudy</span>$<span class="no">Subject</span>))
<span class="no">d</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">y</span>)/<span class="no">n</span>
<span class="no">nrandom</span> <span class="kw">&lt;-</span> <span class="fl">1</span>

<span class="co">##########</span>
<span class="co"># intercept</span>
<span class="no">Z</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/kronecker.html">kronecker</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span>(<span class="no">n</span>), <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">1</span>, <span class="no">d</span>), <span class="kw">ncol</span><span class="kw">=</span><span class="fl">1</span>))</pre></body></html></div>
<p>To compare results, we first fit a linear mixed effects model using the frequentist package <strong>lme4</strong> (Bates et. al. 2015).</p>
<div class="sourceCode" id="cb3"><html><body><pre class="r"><span class="co"># random intercept </span>

<span class="co">## linear mixed models - reference values from older code</span>
(<span class="no">fm1</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmer.html">lmer</a></span>(<span class="no">Reaction</span> ~ <span class="no">Days</span> + (<span class="fl">1</span> <span class="kw">|</span> <span class="no">Subject</span>), <span class="no">sleepstudy</span>, <span class="kw">REML</span> <span class="kw">=</span> <span class="fl">FALSE</span>))
<span class="co">#&gt; Linear mixed model fit by maximum likelihood  ['lmerMod']</span>
<span class="co">#&gt; Formula: Reaction ~ Days + (1 | Subject)</span>
<span class="co">#&gt;    Data: sleepstudy</span>
<span class="co">#&gt;       AIC       BIC    logLik  deviance  df.resid </span>
<span class="co">#&gt; 1802.0786 1814.8505 -897.0393 1794.0786       176 </span>
<span class="co">#&gt; Random effects:</span>
<span class="co">#&gt;  Groups   Name        Std.Dev.</span>
<span class="co">#&gt;  Subject  (Intercept) 36.01   </span>
<span class="co">#&gt;  Residual             30.90   </span>
<span class="co">#&gt; Number of obs: 180, groups:  Subject, 18</span>
<span class="co">#&gt; Fixed Effects:</span>
<span class="co">#&gt; (Intercept)         Days  </span>
<span class="co">#&gt;      251.41        10.47</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">fm1</span>)
<span class="co">#&gt; Linear mixed model fit by maximum likelihood  ['lmerMod']</span>
<span class="co">#&gt; Formula: Reaction ~ Days + (1 | Subject)</span>
<span class="co">#&gt;    Data: sleepstudy</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span>
<span class="co">#&gt;   1802.1   1814.9   -897.0   1794.1      176 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Scaled residuals: </span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -3.2347 -0.5544  0.0155  0.5257  4.2648 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Random effects:</span>
<span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span>
<span class="co">#&gt;  Subject  (Intercept) 1296.9   36.01   </span>
<span class="co">#&gt;  Residual              954.5   30.90   </span>
<span class="co">#&gt; Number of obs: 180, groups:  Subject, 18</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Fixed effects:</span>
<span class="co">#&gt;             Estimate Std. Error t value</span>
<span class="co">#&gt; (Intercept) 251.4051     9.5062   26.45</span>
<span class="co">#&gt; Days         10.4673     0.8017   13.06</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Correlation of Fixed Effects:</span>
<span class="co">#&gt;      (Intr)</span>
<span class="co">#&gt; Days -0.380</span></pre></body></html></div>
</div>
<div id="parameterization-for-g" class="section level1">
<h1 class="hasAnchor">
<a href="#parameterization-for-g" class="anchor"></a>Parameterization for <span class="math inline">\(G\)</span>
</h1>
<p>The parameterization approach for this model uses a strategy recommended by Betancourt, Girolami (2013) to facilitate more efficient sampling in HMC.</p>
<p>Further, the uniform parameterization of the variance parameters is replaced by a half-t family of distributions per Gelman (2006), Prior distributions for Variance parameters in hierarchical models. This parameterization is well-behaved around 0, in contrast to inverse gamma, and provides flexibility for more informed priors than a uniform distribution.</p>
<p>We select a parameterization of <span class="math inline">\(G\)</span> such that the likelihood and its gradient can be derived for HMC. To this end, we uses LDL decomposition of <span class="math inline">\(G\)</span> to form a flexibile parameterization that can easily handle restrictions (Chan, Jelizkov 2009).</p>
<p><span class="math display">\[
\begin{aligned}
u &amp;\sim N(0, G)  \\
G &amp;= L D L^T \\
&amp;= L D^{1/2} D^{1/2} L^T \\
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(\lambda_k\)</span> where <span class="math inline">\(k = 1, ... p\)</span> denote the diagonal entries of <span class="math inline">\(D^{1/2}\)</span> and let <span class="math inline">\(a_{kj}\)</span> where <span class="math inline">\(1 \leq j &lt; k \leq p\)</span> denote free elements of lower unitrangular matrix <span class="math inline">\(L\)</span></p>
<p><span class="math display">\[
D^{1/2} := 
\begin{pmatrix}
\lambda_1 &amp; 0 &amp; ... &amp; 0 \\
0 &amp; \lambda_2 &amp; 0 ... &amp; 0 \\
... &amp; ... &amp; ... &amp; ... \\
0 &amp; 0 &amp; ... &amp; \lambda_p
\end{pmatrix}, 
L :=
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; ... &amp; 0 \\
a_{21} &amp; 1 &amp; 0 &amp; ... &amp; 0 \\
a_{31} &amp; a_{32} &amp; 1 &amp; ... &amp; ... \\
... &amp; ... &amp; ... &amp; ... &amp; ... \\
a_{p1} &amp; a_{p2} &amp; ... &amp; ... &amp; 1 \\
\end{pmatrix}
\]</span></p>
<p>Also define <span class="math inline">\(\lambda := (\lambda_1, ..., \lambda_p)^T\)</span> and <span class="math inline">\(a_k := (a_{k1}, ..., a_{k, k-1})^T\)</span> and <span class="math inline">\(a := (a_2^T, ..., a_p^T)^T\)</span></p>
<p>Consider priors where <span class="math inline">\(k = 1...p\)</span>. The prior for <span class="math inline">\(\lambda_k\)</span> is half-t per Gelman (2006).</p>
<p><span class="math display">\[
\begin{aligned}
p(\lambda_k) &amp;\sim \left(1 + \frac{1}{\nu}\left(\frac{\lambda_k}{A} \right)^2 \right)^{-(\nu+1)/2} \\
a|\lambda &amp;\sim N(a_0, A_0)
\end{aligned}
\]</span></p>
<p>The hyperparameter <span class="math inline">\(a_0\)</span> does not need to be zero, and <span class="math inline">\(A_0\)</span> can be correlated and may depend on <span class="math inline">\(\lambda\)</span>. In this model, we define <span class="math inline">\(a\)</span> independent of <span class="math inline">\(\lambda\)</span>.</p>
<p>Per Betancourt, Girolami (2013), we re-parameterize <span class="math inline">\(u\)</span> using a standard normal parameterization we define as <span class="math inline">\(\tau = (\tau_1, ..., \tau_q)\)</span>. Here, <span class="math inline">\(u\)</span> is a deterministic function of <span class="math inline">\(G\)</span> and <span class="math inline">\(\tau\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\tau &amp;\sim N(0, I_q) \\
u &amp;:= L D^{1/2} \tau \\
&amp;\sim N(0, LD^{1/2} I (L D^{1/2})^T) \\
&amp;\sim N(0, L D^{1/2} D^{1/2} L^T) \\
&amp;\sim N(0, G)
\end{aligned}
\]</span></p>
<p>The distribution of <span class="math inline">\(u\)</span> therefore does not change with this parameterization. The intent of our re-parameterization is to allow <span class="math inline">\(G\)</span> and <span class="math inline">\(\tau\)</span> to be largely independent in the MCMC sampling.</p>
</div>
<div id="derive-the-log-posterior-and-gradient" class="section level1">
<h1 class="hasAnchor">
<a href="#derive-the-log-posterior-and-gradient" class="anchor"></a>Derive the log posterior and gradient</h1>
<p>First, we specify the likelihood and log-likelihood</p>
<p><span class="math display">\[
\begin{aligned}
p(y | \beta, u_1, ..., u_c, \sigma_\epsilon^2) &amp;\propto (\sigma_\epsilon^2)^{-n/2} e^{-\frac{1}{2\sigma_\epsilon^2}(y - X\beta - Zu)^T (y - X\beta - Zu)} \\
\log p(y | \beta, u_1, ..., u_c, \sigma_\epsilon^2) &amp;\propto -{n}\log(\sigma_\epsilon) -\frac{1}{2\sigma_\epsilon^2}(y - X\beta - Zu)^T (y - X\beta - Zu)
\end{aligned}
\]</span></p>
<p>The posterior is defined for priors on <span class="math inline">\(\beta\)</span>, <span class="math inline">\(u\)</span>, <span class="math inline">\(\sigma_\epsilon^2\)</span>, and <span class="math inline">\(G\)</span>, with dependent vector <span class="math inline">\(y\)</span> and design matrices <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
p(\beta, u, \sigma_\epsilon^2, G | y, X, Z) &amp;\propto p(y | \beta, u, \sigma_\epsilon^2, G)  p(\beta, u, \sigma_\epsilon^2, G) \\
&amp;\propto p(y | \beta, u, \sigma_\epsilon^2, G) p(\beta) p(\sigma_\epsilon^2) p(u, G) \\
&amp;\propto p(y | \beta, u, \sigma_\epsilon^2, G) p(\beta) p(\sigma_\epsilon^2) p(u | G) p(G) \\
\log p(\beta, u, \sigma_\epsilon^2, G | y, X, Z) &amp;\propto \log p(y | \beta, u, \sigma_\epsilon^2, G) + \log p(\beta) + \log p(\sigma_\epsilon^2)+ \log p(u|G) + \log p(G) \\
\log p(\beta, \sigma_\epsilon, \tau, \lambda_1...\lambda_q,a | y, X, Z) &amp;\propto \log p(y | \beta, \tau, \sigma_\epsilon, \lambda, a) + \log p(\beta) + \log p(\sigma_\epsilon)+ \log p(\tau) + \log p(\lambda) + \log p(a)
\end{aligned}
\]</span></p>
<p>We parameterize all standard deviations from the half-t family.</p>
<p><span class="math display">\[
\begin{aligned}
p(\beta) &amp;\propto N(0, BI) \\
p(\sigma_\epsilon) &amp;\sim  \left(1 + \frac{1}{\nu_\epsilon}\left(\frac{\sigma_\epsilon}{A_\epsilon} \right)^2 \right)^{-(\nu_\epsilon+1)/2}  \\
p(\lambda_k) &amp;\sim  \left(1 + \frac{1}{\nu_{\lambda_k}}\left(\frac{\lambda_k}{A_{\lambda_k}} \right)^2 \right)^{-(\nu_{\lambda_k}+1)/2}  \\
a &amp;\sim N(0, A_a)
\end{aligned}
\]</span></p>
<p>We want proposals of <span class="math inline">\(\sigma_\epsilon^2\)</span> over the real number line. Therfore we derive the distribution of the transformed parameter <span class="math inline">\(\gamma\)</span> based on a change of variable</p>
<p><span class="math display">\[
\begin{aligned}
\gamma &amp;:= \log \sigma_\epsilon \\
e^\gamma &amp;= \sigma_\epsilon 
\end{aligned}
\]</span></p>
<p>We need to compute the Jacobian of the transformation</p>
<p><span class="math display">\[
\begin{aligned}
p_{\gamma}(\gamma) &amp;= p_{\sigma_\epsilon}(g^{-1}(\gamma))\lvert \frac{d\sigma_\epsilon}{d\gamma} \rvert \\
&amp;= \left(1 + \frac{1}{\nu_\epsilon} \left(\frac{e^\gamma}{A_\epsilon} \right)^2 \right)^{-\frac{\nu_\epsilon +1}{2}} e^{\gamma} \\
&amp;= \left(1 + \frac{1}{\nu_\epsilon} \frac{e^{2\gamma}}{A_\epsilon^2} \right)^{-\frac{\nu_\epsilon +1}{2}} e^{\gamma} \\
\log p_{\gamma}(\gamma) &amp;\propto -\frac{\nu_\epsilon+1}{2}\log\left(1 + \frac{1}{\nu_\epsilon} \frac{e^{2\gamma}}{A_\epsilon^2} \right) + \gamma
\end{aligned}
\]</span></p>
<p>We have hyperpriors <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(a\)</span> for <span class="math inline">\(G\)</span>.</p>
<p>Re-parameterize <span class="math inline">\(\xi_k = \log \lambda_k\)</span> and <span class="math inline">\(e^{\xi_k} = \lambda_k\)</span></p>
<p>Recall that we parameterized <span class="math inline">\(\lambda_k\)</span> as uniform</p>
<p><span class="math display">\[
\begin{aligned}
\lambda_k &amp;\sim \text{half-t}(\nu_{\lambda_k}, A_{\lambda_k}) \\
p_{\xi_k}(\xi_k) &amp;= p_{\lambda_k}(g^{-1}(\xi_k)) \left\lvert \frac{d\lambda_k}{d\xi_k}  \right\rvert \\
&amp;= p_{\lambda_k} (e^{\xi_k})\lvert e^{\xi_k}\rvert \\
&amp;= \left(1 + \frac{1}{\nu_{\lambda_k}} \frac{e^{2\xi_k}}{A_{\lambda_k}^2}\right)^{-\frac{\nu_{\lambda_k}+1}{2}}e^{\xi_k} \\
\log p(\xi_k) &amp;\propto -\frac{\nu_{\lambda_k}+1}{2}\log\left(1 + \frac{1}{\nu_{\lambda_k}} \frac{e^{2\xi_k}}{A_{\lambda_k}^2}\right)+ \xi_k
\end{aligned}
\]</span></p>
<p>Leveraging an idea from Chan, Jeliazkov (2009) MCMC estimation of restricted covariance matrices</p>
<p>We write the matrix form of <span class="math inline">\(u = L D^{1/2} \tau\)</span> in a form with a parameter vector <span class="math inline">\(a\)</span> by which the gradient can be computed directly</p>
<p><span class="math display">\[
\begin{aligned}
u &amp;= L D^{1/2} \tau \\
&amp;= \widetilde{\tau} + \widetilde{T}a \\
&amp;=\begin{pmatrix}
e^\xi_1\tau_1 \\
e^\xi_2\tau_2 \\
e^\xi_3\tau_3 \\
... \\
... \\
e^\xi_q\tau_q
\end{pmatrix} + 
\begin{pmatrix}
0 &amp; ... &amp; &amp; &amp; &amp; &amp; &amp; ... &amp; 0 \\
e^{\xi_1}\tau_1 &amp; 0 &amp; ... &amp; &amp; &amp; &amp; &amp; &amp; ... \\
0 &amp; e^{\xi_1}\tau_1 &amp; e^{\xi_2}\tau_2 &amp; 0 &amp; ... &amp; &amp; &amp; &amp; 0 \\
0 &amp; ... &amp; 0 &amp; e^{\xi_1}\tau_1 &amp; e^{\xi_2}\tau_2 &amp; e^{\xi_3}\tau_3 &amp; 0 &amp; ... &amp; ... \\
... &amp; ... &amp; ... &amp; ... &amp; ... &amp; ... &amp; ... &amp; ... &amp; ... \\
0 &amp; ... &amp; ... &amp; 0 &amp; ... &amp; ... &amp; e^{\xi_1}\tau_1 &amp; ... &amp; e^{\xi_q}\tau_q \\
\end{pmatrix}
\begin{pmatrix}
a_{21} \\
a_{31} \\
a_{32} \\
... \\
... \\
a_{q,q-1}
\end{pmatrix}
\end{aligned}
\]</span></p>
<p>Since we decompose <span class="math inline">\(G\)</span> using <span class="math inline">\(L D L^T\)</span>. We make use of the determinant property of a square matrix, where the determinant of a square matrix is equal to the determinant of its transpose. Also, from above <span class="math inline">\(\lvert L \rvert = 1\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\lvert G \rvert &amp;= \lvert L D L^T \rvert \\
&amp;= \lvert L \rvert \lvert D \rvert \lvert L^T \rvert \\
&amp;= \lvert D \rvert \\
&amp;= \prod_{k=1}^q e^{2\xi_k} \\
&amp;= e^{2\sum_{k=1}^q \xi_k} \\
\log \lvert G \rvert &amp;= 2\sum_{k=1}^q \xi_k
\end{aligned}
\]</span></p>
<p>Assign relatively uniformative prior for <span class="math inline">\(a\)</span></p>
<p><span class="math display">\[
\begin{aligned}
a_k &amp;\sim N(0, A) \\
p(a_k) &amp;\propto \lvert A  \rvert^{-1/2} e^{-\frac{1}{2} a_k^T A^{-1} a_k} \\
\log p(a_k) &amp;\propto -\frac{1}{2}a_k^T A^{-1} a_k
\end{aligned}
\]</span></p>
<p>Recall that the prior for <span class="math inline">\(\tau\)</span> is standard Normal (multivariate)</p>
<p><span class="math display">\[
\begin{aligned}
\tau &amp;\sim N(0, I) \\
p(\tau) &amp;\sim e^{-\frac{1}{2}\tau^T I \tau} \\
\log p(\tau) &amp;\sim -\frac{1}{2} \tau^T \tau
\end{aligned}
\]</span></p>
<p>Finally, we write the full log posterior</p>
<p><span class="math display">\[
\begin{aligned}
\log p(\beta, \sigma_\epsilon, \tau, \lambda_1...\lambda_q,a | y, X, Z) &amp;\propto \log p(y | \beta, \tau, \sigma_\epsilon, \lambda, a) + \log p(\beta) + \log p(\sigma_\epsilon)+ \log p(\tau) + \log p(\lambda) + \log p(a) \\
\log p(\beta, \gamma, \tau, \xi_1...\xi_q,a | y, X, Z) &amp;\propto \log p(y | \beta, \tau, \gamma, \xi, a) + \log p(\beta) + \log p(\gamma)+ \log p(\tau) + \log p(\xi) + \log p(a) \\
&amp;\propto  -n\gamma -\frac{e^{-2\gamma}}{2}(y - X\beta - Zu)^T (y - X\beta - Zu)  - \frac{1}{2}\beta^T\Sigma_\beta^{-1}\beta \\
&amp;-\frac{\nu_\epsilon+1}{2}\log\left(1 + \frac{1}{\nu_\epsilon} \frac{e^{2\gamma}}{A_\epsilon^2} \right) + \gamma  -\frac{1}{2} a^T A^{-1} a -\frac{1}{2} \tau^T \tau\\
&amp;-\sum_{k=1}^q \left(\frac{\nu_{\lambda_k}+1}{2}\log\left(1 + \frac{1}{\nu_{\lambda_k}} \frac{e^{2\xi_k}}{A_{\lambda_k}^2}\right)+ \xi_k\right)\\
&amp;\propto  -n\gamma -\frac{e^{-2\gamma}}{2}(y - X\beta - ZL D^{1/2}\tau)^T (y - X\beta - ZL D^{1/2}\tau) - \frac{1}{2}\beta^T\Sigma_\beta^{-1}\beta \\
&amp;-\frac{\nu_\epsilon+1}{2}\log\left(1 + \frac{1}{\nu_\epsilon} \frac{e^{2\gamma}}{A_\epsilon^2} \right) + \gamma  -\frac{1}{2} a^T A^{-1} a -\frac{1}{2} \tau^T \tau\\
&amp;-\sum_{k=1}^q \left(\frac{\nu_{\lambda_k}+1}{2}\log\left(1 + \frac{1}{\nu_{\lambda_k}} \frac{e^{2\xi_k}}{A_{\lambda_k}^2}\right)+ \xi_k\right)\\
\end{aligned}
\]</span></p>
<div id="derive-the-gradient-of-the-log-posterior" class="section level2">
<h2 class="hasAnchor">
<a href="#derive-the-gradient-of-the-log-posterior" class="anchor"></a>Derive the gradient of the log posterior</h2>
<p>Derive the partial derivative of <span class="math inline">\(\tau\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial l}{\partial\tau} &amp;\propto \frac{\partial}{\partial\tau}\left(-\frac{e^{-2\gamma}}{2}(y-X\beta-ZLD^{1/2}\tau)^T(y-X\beta-ZLD^{1/2}\tau) - \frac{1}{2}\tau^T\tau\right) \\
&amp;\propto e^{-2\gamma}(ZLD^{1/2})^T (y-X\beta-ZLD^{1/2}\tau) - \tau \\
&amp;\propto e^{-2\gamma} D^{1/2}L^T Z^T(y - X\beta - ZLD^{1/2}\tau) - 1
\end{aligned}
\]</span></p>
<p>Derive the partial derivative of <span class="math inline">\(\xi_k\)</span>. Here <span class="math inline">\(J^{kk}\)</span> is the singular entry matrix of <span class="math inline">\(e^{\xi_k}\)</span> at <span class="math inline">\(kk\)</span>, with the remaining matrix elements zero.</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial l}{\partial\xi_k} &amp;\propto \frac{\partial}{\partial\xi_k}\left(-\frac{e^{-2\gamma}}{2}(y-X\beta-ZLD^{1/2}\tau)^T(y - X\beta-ZLD^{1/2}\tau) - \frac{\nu_{\lambda_k}+1}{2}\log\left(1 + \frac{1}{\nu_{\lambda_k}}\frac{e^{2\xi_k}}{A_{\lambda_k}^2} \right) +\xi_k\right) \\
&amp;\propto e^{-2\gamma} \text{tr}\left((y - X\beta - ZLD^{1/2}\tau) (Z L J^{kk} \tau)^T\right) - (\nu_{\lambda_k}+1)\frac{1}{1 + \nu_{\lambda_k}A_{\lambda_k}^2 e^{-2\xi_k}}+1
\end{aligned}
\]</span></p>
<p>Derive the partial derivative with respect to <span class="math inline">\(a\)</span>.</p>
<p>Note that the following are equivalent</p>
<p><span class="math display">\[
\begin{aligned}
L D^{1/2}\tau = D^{1/2} \tau + \widetilde{T} a
\end{aligned}
\]</span></p>
<p>Therefore, the portion of the log likelihood dependent on <span class="math inline">\(a\)</span> becomes</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial l}{\partial a} &amp;\propto \frac{\partial}{\partial a}\left(-\frac{e^{-2\gamma}}{2}(y-X\beta - \widetilde\tau - \widetilde{T}a)^T(y-X\beta - \widetilde\tau - \widetilde{T}a) -\frac{1}{2}a^T A^{-1} a \right) \\
&amp;\propto e^{-2\gamma} \widetilde{T}^T(y-X\beta-\widetilde\tau - \widetilde{T}a) - A^{-1}a 
\end{aligned}
\]</span></p>
<p>The gradient of full log posterior can now be specified</p>
<p><span class="math display">\[
\begin{aligned}
\log p(\beta, \gamma, \tau, \xi_1...\xi_q,a | y, X, Z) &amp;\propto \log p(y | \beta, \tau, \gamma, \xi, a) + \log p(\beta) + \log p(\gamma)+ \log p(\tau) + \log p(\xi) + \log p(a) \\
&amp;\propto  -n\gamma -\frac{e^{-2\gamma}}{2}(y - X\beta - ZLD^{1/2}\tau)^T (y - X\beta - ZLD^{1/2}\tau)  -\frac{1}{2}\beta^T\Sigma_\beta^{-1}\beta\\
&amp;-\frac{\nu_\epsilon+1}{2}\log\left(1 + \frac{1}{\nu_\epsilon} \frac{e^{2\gamma}}{A_\epsilon^2} \right) + \gamma  -\frac{1}{2} a^T A^{-1} a -\frac{1}{2} \tau^T \tau\\
&amp;-\sum_{k=1}^q \left(\frac{\nu_{\lambda_k}+1}{2}\log\left(1 + \frac{1}{\nu_{\lambda_k}} \frac{e^{2\xi_k}}{A_{\lambda_k}^2}\right)+ \xi_k\right)\\
\frac{\partial l}{\partial\beta} &amp;= e^{-2\gamma}X^T(y-X\beta-ZLD^{1/2}\tau)-\Sigma_\beta^{-1}\beta \\
\frac{\partial l}{\partial\gamma} &amp;= -(n-1)+e^{-2\gamma}(y-X\beta-ZLD^{1/2}\tau)^T(y-X\beta-ZLD^{1/2}\tau) \\
&amp;-(\nu_\epsilon + 1) \frac{1}{1 + \nu_\epsilon A_\epsilon^2 e^{-2\gamma}} \\
\frac{\partial l}{\partial\tau} &amp;=  e^{-2\gamma} D^{1/2}L^T Z^T(y - X\beta - ZLD^{1/2}\tau) - \tau\\
\frac{\partial l}{\partial\xi_k} &amp;=  e^{-2\gamma}\text{tr}\left((y - X\beta - ZLD^{1/2}\tau) (Z L J^{kk} \tau)^T\right) - (\nu_{\lambda_k}+1)\frac{1}{1 + \nu_{\lambda_k}A_{\lambda_k}^2 e^{-2\xi_k}}+1  \\
\frac{\partial l}{\partial a} &amp;= e^{-2\gamma}\widetilde{T}^T Z^T(y - X\beta-ZD^{1/2}\tau - Z\widetilde{T}a) - A^{-1}a 
\end{aligned}
\]</span></p>
</div>
</div>
<div id="hamiltonian-monte-carlo" class="section level1">
<h1 class="hasAnchor">
<a href="#hamiltonian-monte-carlo" class="anchor"></a>Hamiltonian Monte Carlo</h1>
<p>Run HMC for linear mixed effects regression model</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="no">N</span> <span class="kw">&lt;-</span> <span class="fl">2e3</span>

<span class="no">theta.init</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0</span>, <span class="fl">1</span>, <span class="co"># beta </span>
               <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">0</span>, <span class="fl">18</span>), <span class="co"># tau</span>
               <span class="fl">3</span>, <span class="co"># gamma (log sig2eps)</span>
               <span class="fl">1</span>) <span class="co"># xi </span>

<span class="no">vnames</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span>(<span class="st">"beta"</span>, <span class="fl">0</span>:<span class="fl">1</span>),
            <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span>(<span class="st">"tau_int"</span>, <span class="fl">1</span>:<span class="fl">18</span>),
           <span class="st">"sigeps"</span>, <span class="st">"xi"</span>)

<span class="no">eps_vals</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">5e-1</span>, <span class="fl">5e-2</span>,
              <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">3e-2</span>, <span class="fl">18</span>),
              <span class="fl">6e-3</span>,
              <span class="fl">5e-2</span>)

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">41132</span>)
<span class="no">t1.hmc</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html">Sys.time</a></span>()
 <span class="no">f_hmc</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/hmc.html">hmc</a></span>(<span class="kw">N</span> <span class="kw">=</span> <span class="no">N</span>, <span class="kw">theta.init</span> <span class="kw">=</span> <span class="no">theta.init</span>,
               <span class="kw">epsilon</span> <span class="kw">=</span> <span class="no">eps_vals</span>, <span class="kw">L</span> <span class="kw">=</span> <span class="fl">10</span>,
               <span class="kw">logPOSTERIOR</span> <span class="kw">=</span> <span class="no">lmm_posterior</span>,
               <span class="kw">glogPOSTERIOR</span> <span class="kw">=</span> <span class="no">g_lmm_posterior</span>,
               <span class="kw">varnames</span> <span class="kw">=</span> <span class="no">vnames</span>,
               <span class="kw">param</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">y</span>, <span class="kw">X</span><span class="kw">=</span><span class="no">X</span>, <span class="kw">Z</span><span class="kw">=</span><span class="no">Z</span>, <span class="kw">n</span><span class="kw">=</span><span class="no">n</span>, <span class="kw">d</span><span class="kw">=</span><span class="no">d</span>, <span class="kw">nrandom</span><span class="kw">=</span><span class="fl">1</span>,
                          <span class="kw">nugamma</span><span class="kw">=</span><span class="fl">4</span>, <span class="kw">Agamma</span><span class="kw">=</span><span class="fl">1</span>,
                          <span class="kw">nuxi</span><span class="kw">=</span><span class="fl">1</span>, <span class="kw">Axi</span><span class="kw">=</span><span class="fl">1</span>, <span class="kw">sig2beta</span><span class="kw">=</span><span class="fl">1e5</span>),
               <span class="kw">parallel</span><span class="kw">=</span><span class="fl">FALSE</span>, <span class="kw">chains</span><span class="kw">=</span><span class="fl">2</span>)
<span class="no">t2.hmc</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html">Sys.time</a></span>()
<span class="no">t2.hmc</span> - <span class="no">t1.hmc</span>
<span class="co">#&gt; Time difference of 1.06623 mins</span></pre></body></html></div>
<p>The acceptance ratio for each of the HMC chains is sufficiently high for an efficient simulation.</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="no">f_hmc</span>$<span class="no">accept</span>/<span class="no">N</span>
<span class="co">#&gt; [1] 0.814 0.805</span></pre></body></html></div>
<p>Trace plots provide a visual indication of stationarity. These plots indicate that the MCMC chains are reasonably stationary.</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="fu"><a href="../reference/hmclearn-plots.html">mcmc_trace</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">trunc</a></span>(<span class="no">N</span>*<span class="fl">.3</span>), <span class="kw">pars</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"beta0"</span>, <span class="st">"beta1"</span>, <span class="st">"sigeps"</span>, <span class="st">"xi"</span>))</pre></body></html></div>
<p><img src="linear_mixed_effects_hmclearn_files/figure-html/unnamed-chunk-6-1.png" width="576"></p>
<p>The posterior quantiles are summarized after removing an initial <em>burnin</em> period.</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">trunc</a></span>(<span class="no">N</span>*<span class="fl">.3</span>))
<span class="co">#&gt; Summary of MCMC simulation</span>
<span class="co">#&gt;                      5%          25%           50%         75%          95%</span>
<span class="co">#&gt; beta0      2.327944e+02 241.89217307 248.352552693 253.7295718 263.17481417</span>
<span class="co">#&gt; beta1      9.328444e+00  10.04105950  10.532795892  11.0469884  11.82741944</span>
<span class="co">#&gt; tau_int1   6.213171e-01   0.93359832   1.167452224   1.4397057   1.83370042</span>
<span class="co">#&gt; tau_int2  -2.809036e+00  -2.33009109  -2.020047420  -1.7439651  -1.33534270</span>
<span class="co">#&gt; tau_int3  -2.366965e+00  -1.92402317  -1.628754913  -1.3584329  -0.99843222</span>
<span class="co">#&gt; tau_int4  -3.449023e-01  -0.02246452   0.195555766   0.4249330   0.74445445</span>
<span class="co">#&gt; tau_int5  -1.601095e-01   0.14702177   0.357780409   0.5712771   0.94290556</span>
<span class="co">#&gt; tau_int6  -2.106870e-01   0.08983899   0.288832127   0.4998416   0.86177250</span>
<span class="co">#&gt; tau_int7   3.075246e-04   0.32130309   0.521949974   0.7341278   1.06812066</span>
<span class="co">#&gt; tau_int8  -5.250118e-01  -0.20483523  -0.002182091   0.1992217   0.50840065</span>
<span class="co">#&gt; tau_int9  -1.799009e+00  -1.41391783  -1.147736157  -0.8954078  -0.52859063</span>
<span class="co">#&gt; tau_int10  1.348615e+00   1.73018898   2.013683784   2.3463818   2.79418829</span>
<span class="co">#&gt; tau_int11 -1.053962e+00  -0.71512168  -0.503604123  -0.2805310   0.03102414</span>
<span class="co">#&gt; tau_int12 -5.984324e-02   0.24471072   0.463964937   0.6880517   1.02133903</span>
<span class="co">#&gt; tau_int13 -6.890123e-01  -0.34115241  -0.107625210   0.1020035   0.41003730</span>
<span class="co">#&gt; tau_int14  5.277042e-01   0.82337594   1.045747168   1.2923674   1.67376662</span>
<span class="co">#&gt; tau_int15 -2.675430e-01   0.05652652   0.263111730   0.5034956   0.84116476</span>
<span class="co">#&gt; tau_int16 -6.108352e-01  -0.30877607  -0.079167619   0.1401596   0.47023929</span>
<span class="co">#&gt; tau_int17 -5.363645e-01  -0.23346035  -0.008004814   0.1981716   0.50581182</span>
<span class="co">#&gt; tau_int18  3.483494e-02   0.35543901   0.554203574   0.7780795   1.15456654</span>
<span class="co">#&gt; sigeps     3.335228e+00   3.38724086   3.420776537   3.4602352   3.51289370</span>
<span class="co">#&gt; xi         3.330004e+00   3.48419242   3.599906725   3.7252319   3.92390056</span>
<span class="co">#&gt;                rhat</span>
<span class="co">#&gt; beta0     1.0001273</span>
<span class="co">#&gt; beta1     1.0152341</span>
<span class="co">#&gt; tau_int1  1.0006277</span>
<span class="co">#&gt; tau_int2  1.0136249</span>
<span class="co">#&gt; tau_int3  1.0033839</span>
<span class="co">#&gt; tau_int4  1.0040567</span>
<span class="co">#&gt; tau_int5  0.9996973</span>
<span class="co">#&gt; tau_int6  1.0019383</span>
<span class="co">#&gt; tau_int7  1.0004302</span>
<span class="co">#&gt; tau_int8  0.9997383</span>
<span class="co">#&gt; tau_int9  1.0020873</span>
<span class="co">#&gt; tau_int10 1.0036116</span>
<span class="co">#&gt; tau_int11 1.0047227</span>
<span class="co">#&gt; tau_int12 0.9996900</span>
<span class="co">#&gt; tau_int13 1.0025572</span>
<span class="co">#&gt; tau_int14 1.0016279</span>
<span class="co">#&gt; tau_int15 0.9998920</span>
<span class="co">#&gt; tau_int16 0.9996697</span>
<span class="co">#&gt; tau_int17 1.0002093</span>
<span class="co">#&gt; tau_int18 1.0051712</span>
<span class="co">#&gt; sigeps    0.9998044</span>
<span class="co">#&gt; xi        1.0162299</span></pre></body></html></div>
<p>Histograms of the posterior distribution show that Bayesian parameter estimates align with frequentist estimates. The <em>cols</em> parameter specifies the parameters to be displayed in <em>diagplots</em>, based on the order provided to the <em>hmc</em> function.</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="no">beta.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/fixef.html">fixef</a></span>(<span class="no">fm1</span>)
<span class="no">xi.freq</span> <span class="kw">&lt;-</span> <span class="fl">1</span>/<span class="fl">2</span>*<span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span>(<span class="fu"><a href="https://rdrr.io/pkg/lme4/man/VarCorr.html">VarCorr</a></span>(<span class="no">fm1</span>)$<span class="no">Subject</span>[<span class="fl">1</span>])
<span class="no">sigeps.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span>(<span class="fu"><a href="https://rdrr.io/pkg/lme4/man/sigma.html">sigma</a></span>(<span class="no">fm1</span>))
<span class="no">theta.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="no">beta.freq</span>, <span class="no">sigeps.freq</span>, <span class="no">xi.freq</span>)
<span class="fu"><a href="../reference/diagplots.html">diagplots</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">trunc</a></span>(<span class="no">N</span>*<span class="fl">.3</span>),
          <span class="kw">actual.mu</span><span class="kw">=</span><span class="no">theta.freq</span>, <span class="kw">cols</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">1</span>:<span class="fl">2</span>, <span class="fl">21</span>:<span class="fl">22</span>))
<span class="co">#&gt; $histogram</span></pre></body></html></div>
<p><img src="linear_mixed_effects_hmclearn_files/figure-html/unnamed-chunk-8-1.png" width="576"></p>
</div>
<div id="source" class="section level1">
<h1 class="hasAnchor">
<a href="#source" class="anchor"></a>Source</h1>
<p>Gregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. <em>Journal of Sleep Research</em> 12, 1–12.</p>
</div>
<div id="references" class="section level1">
<h1 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h1>
<p>Bates, D., M"{a}chler, M., Bolker, B., &amp; Walker, S. (2015). Fitting linear mixed-effects models using lme4. <em>Journal of Statistical Software</em> 67(1)</p>
<p>Betancourt, M., &amp; Girolami, M. (2015). Hamiltonian Monte Carlo for hierarchical models. <em>Current trends in Bayesian methodology with applications</em>, 79(30), 2-4.</p>
<p>Gelman, Andrew. (2006) “Prior distributions for variance parameters in hierarchical models (comment on article by Browne and Draper).” <em>Bayesian analysis</em> 1.3: 515-534.</p>
<p>Chan, J. C. C., &amp; Jeliazkov, I. (2009). MCMC estimation of restricted covariance matrices. <em>Journal of Computational and Graphical Statistics</em>, 18(2), 457-480.</p>
<p>Agresti, A. (2015). <em>Foundations of linear and generalized linear models</em>. John Wiley &amp; Sons. ISBN: 978-1-118-73003-4</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Samuel Thomas.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.9000.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
