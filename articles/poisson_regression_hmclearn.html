<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>hmclearn:  Poisson Regression Example • hmclearn</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/sandstone/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="hmclearn:  Poisson Regression Example">
<meta property="og:description" content="hmclearn">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">hmclearn</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.5</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/linear_mixed_effects_hmclearn.html">hmclearn:  Linear Mixed Effects Regression Example</a>
    </li>
    <li>
      <a href="../articles/linear_regression_hmclearn.html">hmclearn:  Linear Regression Example</a>
    </li>
    <li>
      <a href="../articles/logistic_mixed_effects_hmclearn.html">hmclearn:  Logistic Mixed Effects Regression Example</a>
    </li>
    <li>
      <a href="../articles/logistic_regression_hmclearn.html">hmclearn:  Logistic Regression Example</a>
    </li>
    <li>
      <a href="../articles/poisson_regression_hmclearn.html">hmclearn:  Poisson Regression Example</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="poisson_regression_hmclearn_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>hmclearn: Poisson Regression Example</h1>
                        <h4 class="author">Samuel Thomas</h4>
            
            <h4 class="date">2020-10-04</h4>
      
      
      <div class="hidden name"><code>poisson_regression_hmclearn.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>This vignette demonstrates fitting a Poisson regression model via Hamiltonian Monte Carlo (HMC) using the <strong>hmclearn</strong> package.</p>
<div class="sourceCode" id="cb1"><pre class="downlit">
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">hmclearn</span><span class="op">)</span></pre></div>
<p>For a count response, we let</p>
<p><span class="math display">\[
p(y | \mu) = \frac{e^{-\mu}\mu^y}{y!},
\]</span></p>
<p>with a log-link function</p>
<p><span class="math display">\[
\begin{aligned}
\boldsymbol\mu &amp;:= E(\mathbf{y} | \mathbf{X}) = e^{\mathbf{X}\boldsymbol\beta}, \\
\log \boldsymbol\mu &amp;= \mathbf{X}\boldsymbol\beta.
\end{aligned}
\]</span> The vector of responses is <span class="math inline">\(\mathbf{y} = (y_1, ..., y_n)^T\)</span>. The covariate values for subject <span class="math inline">\(i\)</span> are <span class="math inline">\(\mathbf{x}_i^T = (x_{i0}, ..., x_{iq})\)</span> for <span class="math inline">\(q\)</span> covariates plus an intercept. We write the full design matrix as <span class="math inline">\(\mathbf{X} = (\mathbf{x}_1^T, ..., \mathbf{x}_n^T)^T \in \mathbb{R}^{n\times(q+1)}\)</span> for <span class="math inline">\(n\)</span> observations. The regression coefficients are a vector of length <span class="math inline">\(q + 1\)</span>, <span class="math inline">\(\boldsymbol\beta = (\beta_0, ..., \beta_q)^T\)</span>.</p>
</div>
<div id="derive-log-posterior-and-gradient-for-hmc" class="section level2">
<h2 class="hasAnchor">
<a href="#derive-log-posterior-and-gradient-for-hmc" class="anchor"></a>Derive log posterior and gradient for HMC</h2>
<p>We develop the likelihood</p>
<p><span class="math display">\[
\begin{aligned}
f(\mathbf{y} | \boldsymbol\mu) &amp;= \prod_{i=1}^n \frac{e^{-\mu_i}\mu_i^{y_i}}{y_i!}, \\
f(\mathbf{y} | \mathbf{X}, \boldsymbol\beta) &amp;= \prod_{i=1}^n \frac{e^{-e^{\mathbf{x}_i^T\boldsymbol\beta}}e^{y_i\mathbf{x}_i^T\boldsymbol\beta}}{y_i!}, \\
\end{aligned}
\]</span></p>
<p>and log-likelihood</p>
<p><span class="math display">\[
\begin{aligned}
f(\mathbf{y} | \mathbf{X}, \boldsymbol\beta) &amp;= \sum_{i=1}^n -e^{\mathbf{x}_i^T\boldsymbol\beta} + y_i \mathbf{x}_i^T \boldsymbol\beta - \log y_i!,  \\
&amp;\propto \sum_{i=1}^n -e^{\mathbf{x}_i^T\boldsymbol\beta} + y_i \mathbf{x}_i^T \boldsymbol\beta.
\end{aligned}
\]</span></p>
<p>We set a multivariate normal prior for <span class="math inline">\(\boldsymbol\beta\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\boldsymbol\beta &amp;\sim N(0, \sigma_\beta^2 \mathbf{I}),
\end{aligned}
\]</span></p>
<p>with pdf, omitting constants</p>
<p><span class="math display">\[
\begin{aligned}
\pi(\boldsymbol\beta | \sigma_\beta^2) &amp;= \frac{1}{\sqrt{\lvert 2\pi \sigma_\beta^2 \rvert }}e^{-\frac{1}{2}\boldsymbol\beta^T \boldsymbol\beta / \sigma_\beta^2},  \\
\log \pi(\boldsymbol\beta | \sigma_\beta^2) &amp;= -\frac{1}{2}\log(2\pi \sigma_\beta^2) - \frac{1}{2}\boldsymbol\beta^T \boldsymbol\beta / \sigma_\beta^2, \\
&amp;\propto -\frac{1}{2}\log \sigma_\beta^2 - \frac{\boldsymbol\beta^T\boldsymbol\beta}{2\sigma_\beta^2}.
\end{aligned}
\]</span></p>
<p>Next, we derive the log posterior, omitting constants,</p>
<p><span class="math display">\[
\begin{aligned}
f(\boldsymbol\beta | \mathbf{X}, \mathbf{y}, \sigma_\beta^2) &amp;\propto f(\mathbf{y} | \mathbf{X}, \boldsymbol\beta) \pi(\boldsymbol\beta | \sigma_\beta^2), \\
\log f(\boldsymbol\beta | \mathbf{X}, \mathbf{y}, \sigma_\beta^2) &amp; \propto \log f(\mathbf{y} | \mathbf{X}, \boldsymbol\beta) + \log \pi(\beta | \sigma_\beta^2), \\
&amp;\propto \sum_{i=1}^n \left( -e^{\mathbf{x}_i^T\boldsymbol\beta} + y_i \mathbf{x}_i^T \boldsymbol\beta\right) - \frac{1}{2}\beta^T\beta/\sigma_\beta^2, \\
&amp;\propto \sum_{i=1}^n \left( -e^{\mathbf{x}_i^T\boldsymbol\beta} + y_i \mathbf{x}_i^T \boldsymbol\beta\right) - \frac{\boldsymbol\beta^T\boldsymbol\beta}{2\sigma_\beta^2}, \\
&amp;\propto \mathbf{y}^T\mathbf{X}\boldsymbol\beta - \mathbf{1}_n^T e^{\mathbf{X}\boldsymbol\beta} - \frac{\boldsymbol\beta^T\boldsymbol\beta}{2\sigma_\beta^2}.
\end{aligned}
\]</span></p>
<p>We need to derive the gradient of the log posterior for the leapfrog function in HMC.</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_{\boldsymbol\beta}\log f(\boldsymbol\beta|\mathbf{X}, \mathbf{y}, \sigma_\beta^2) &amp;\propto \sum_{i=1}^n\left( -e^{\mathbf{x}_i^T\boldsymbol\beta}\mathbf{x}_i + y_i\mathbf{x}_i\right) - \boldsymbol\beta / \sigma_\beta^2, \\
&amp;\propto \sum_{i=1}^n \mathbf{x}_i\left( -e^{\mathbf{x}_i^T\boldsymbol\beta} + y_i\right) - \boldsymbol\beta / \sigma_\beta^2, \\
&amp;\propto \mathbf{X}^T (\mathbf{y} - e^{\mathbf{X}\boldsymbol\beta}) - \boldsymbol\beta/ \sigma_\beta^2.
\end{aligned}
\]</span></p>
</div>
<div id="poisson-regression-example-data" class="section level2">
<h2 class="hasAnchor">
<a href="#poisson-regression-example-data" class="anchor"></a>Poisson Regression Example Data</h2>
<p>The user must define provide the design matrix directly for use in <strong>hmclearn</strong>. Our first step is to load the data and store the design matrix <span class="math inline">\(X\)</span> and dependent variable vector <span class="math inline">\(y\)</span>.</p>
<p>We load drug usage data and create the design matrix <span class="math inline">\(X\)</span> and dependent vector <span class="math inline">\(y\)</span>. This example also appears in Agresti (2015), and we compare results to his.</p>
<div class="sourceCode" id="cb2"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="va">Drugs</span><span class="op">)</span>

<span class="co"># design matrix</span>
<span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="va">count</span> <span class="op">~</span> <span class="va">A</span> <span class="op">+</span> <span class="va">C</span> <span class="op">+</span> <span class="va">M</span> <span class="op">+</span> <span class="va">A</span><span class="op">:</span><span class="va">C</span> <span class="op">+</span> <span class="va">A</span><span class="op">:</span><span class="va">M</span> <span class="op">+</span> <span class="va">C</span><span class="op">:</span><span class="va">M</span> , data<span class="op">=</span><span class="va">Drugs</span><span class="op">)</span>
<span class="va">X</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op">]</span>

<span class="co"># independent variable is count data</span>
<span class="va">y</span> <span class="op">&lt;-</span> <span class="va">Drugs</span><span class="op">$</span><span class="va">count</span></pre></div>
</div>
<div id="comparison-model---frequentist" class="section level2">
<h2 class="hasAnchor">
<a href="#comparison-model---frequentist" class="anchor"></a>Comparison model - Frequentist</h2>
<p>To compare results, we first fit a standard linear model using the frequentist function <em>glm</em>.</p>
<div class="sourceCode" id="cb3"><pre class="downlit">
<span class="co"># matrix representation</span>
<span class="va">f</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">X</span><span class="op">-</span><span class="fl">1</span>, family<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/stats/family.html">poisson</a></span><span class="op">(</span>link<span class="op">=</span><span class="va">log</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">f</span><span class="op">)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = y ~ X - 1, family = poisson(link = log))</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;        1         2         3         4         5         6  </span>
<span class="co">#&gt;  0.02044  -0.02658  -0.09256   0.02890  -0.33428   0.09452  </span>
<span class="co">#&gt;        7         8  </span>
<span class="co">#&gt;  0.49134  -0.03690  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; X(Intercept)  5.63342    0.05970  94.361  &lt; 2e-16 ***</span>
<span class="co">#&gt; XAyes         0.48772    0.07577   6.437 1.22e-10 ***</span>
<span class="co">#&gt; XCyes        -1.88667    0.16270 -11.596  &lt; 2e-16 ***</span>
<span class="co">#&gt; XMyes        -5.30904    0.47520 -11.172  &lt; 2e-16 ***</span>
<span class="co">#&gt; XAyes:Cyes    2.05453    0.17406  11.803  &lt; 2e-16 ***</span>
<span class="co">#&gt; XAyes:Myes    2.98601    0.46468   6.426 1.31e-10 ***</span>
<span class="co">#&gt; XCyes:Myes    2.84789    0.16384  17.382  &lt; 2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 2.4038e+04  on 8  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 3.7399e-01  on 1  degrees of freedom</span>
<span class="co">#&gt; AIC: 63.417</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></pre></div>
</div>
<div id="fit-model-using-hmc" class="section level2">
<h2 class="hasAnchor">
<a href="#fit-model-using-hmc" class="anchor"></a>Fit model using <em>hmc</em>
</h2>
<p>Next, we fit the poisson regression model using HMC. A vector of <span class="math inline">\(\epsilon\)</span> values are specified to align with the data.</p>
<div class="sourceCode" id="cb4"><pre class="downlit">
<span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">1e4</span>

<span class="va">eps_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">5e-4</span>, <span class="fl">2</span><span class="op">)</span>, <span class="fl">1e-3</span>, <span class="fl">2e-3</span>, <span class="fl">1e-3</span>, <span class="fl">2e-3</span>, <span class="fl">5e-4</span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">412</span><span class="op">)</span>
<span class="va">t1.hmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html">Sys.time</a></span><span class="op">(</span><span class="op">)</span>
 <span class="va">f_hmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/hmc.html">hmc</a></span><span class="op">(</span>N <span class="op">=</span> <span class="va">N</span>, theta.init <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">7</span><span class="op">)</span>,
                    epsilon <span class="op">=</span> <span class="va">eps_vals</span>, L <span class="op">=</span> <span class="fl">50</span>,
                    logPOSTERIOR <span class="op">=</span> <span class="va">poisson_posterior</span>,
                    glogPOSTERIOR <span class="op">=</span> <span class="va">g_poisson_posterior</span>,
                    varnames <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span>,
                    parallel<span class="op">=</span><span class="cn">FALSE</span>, chains<span class="op">=</span><span class="fl">2</span>,
                    param<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>y<span class="op">=</span><span class="va">y</span>, X<span class="op">=</span><span class="va">X</span><span class="op">)</span><span class="op">)</span>
<span class="va">t2.hmc</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html">Sys.time</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">t2.hmc</span> <span class="op">-</span> <span class="va">t1.hmc</span>
<span class="co">#&gt; Time difference of 51.99019 secs</span></pre></div>
</div>
<div id="mcmc-summary-and-diagnostics" class="section level2">
<h2 class="hasAnchor">
<a href="#mcmc-summary-and-diagnostics" class="anchor"></a>MCMC summary and diagnostics</h2>
<p>The acceptance ratio for each of the HMC chains is sufficiently high for an efficient simulation.</p>
<div class="sourceCode" id="cb5"><pre class="downlit">
<span class="va">f_hmc</span><span class="op">$</span><span class="va">accept</span><span class="op">/</span><span class="va">N</span>
<span class="co">#&gt; [1] 0.9804 0.9829</span></pre></div>
<p>The posterior quantiles are summarized after removing an initial <em>burnin</em> period. The <span class="math inline">\(\hat{R}\)</span> statistics provide an indication of convergence. Values close to one indicate that the multiple MCMC chains coverged to the same distribution, while values above 1.1 indicate possible convergence problems. All <span class="math inline">\(\hat{R}\)</span> values in our example are close to one.</p>
<div class="sourceCode" id="cb6"><pre class="downlit">
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">f_hmc</span>, burnin<span class="op">=</span><span class="fl">3000</span>, probs<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; Summary of MCMC simulation</span>
<span class="co">#&gt;                   2.5%        50%      97.5%     rhat</span>
<span class="co">#&gt; (Intercept)  5.5238199  5.6327435  5.7521131 1.001527</span>
<span class="co">#&gt; Ayes         0.3379506  0.4875867  0.6251244 1.006951</span>
<span class="co">#&gt; Cyes        -2.2176007 -1.8992300 -1.6078705 1.001525</span>
<span class="co">#&gt; Myes        -6.3840770 -5.3643129 -4.4945189 1.007716</span>
<span class="co">#&gt; Ayes:Cyes    1.7495447  2.0670083  2.4061751 1.005151</span>
<span class="co">#&gt; Ayes:Myes    2.1572253  3.0200944  4.1225859 1.018774</span>
<span class="co">#&gt; Cyes:Myes    2.5174705  2.8574315  3.1983475 1.026709</span></pre></div>
<p>Trace plots provide a visual indication of stationarity. These plots indicate that the MCMC chains are reasonably stationary.</p>
<div class="sourceCode" id="cb7"><pre class="downlit">
<span class="fu"><a href="../reference/hmclearn-plots.html">mcmc_trace</a></span><span class="op">(</span><span class="va">f_hmc</span>, burnin<span class="op">=</span><span class="fl">3000</span><span class="op">)</span></pre></div>
<div class="figure">
<img src="fig1poisson-1.png" alt=""><p class="caption">plot of chunk fig1poisson</p>
</div>
<p>Histograms of the posterior distribution show that Bayesian parameter estimates align with Frequentist estimates.</p>
<div class="sourceCode" id="cb8"><pre class="downlit">
<span class="va">beta.freq</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">f</span><span class="op">)</span>
<span class="fu"><a href="../reference/diagplots.html">diagplots</a></span><span class="op">(</span><span class="va">f_hmc</span>, burnin<span class="op">=</span><span class="fl">3000</span>, comparison.theta<span class="op">=</span><span class="va">beta.freq</span><span class="op">)</span>
<span class="co">#&gt; $histogram</span></pre></div>
<div class="figure">
<img src="fit2poisson-1.png" alt=""><p class="caption">plot of chunk fit2poisson</p>
</div>
</div>
<div id="source" class="section level2">
<h2 class="hasAnchor">
<a href="#source" class="anchor"></a>Source</h2>
<p>Data originally provided by Harry Khamis, Wright State University</p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<p>Agresti, A. (2015). <em>Foundations of linear and generalized linear models</em>. John Wiley &amp; Sons. ISBN: 978-1-118-73003-4</p>
<p>Thomas, Samuel, and Wanzhu Tu. “Learning Hamiltonian Monte Carlo in R.” arXiv preprint arXiv:2006.16194 (2020).</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Samuel Thomas.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.9000.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
