<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>hmclearn:  Logistic Mixed Effects Regression Example • hmclearn</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/sandstone/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="hmclearn:  Logistic Mixed Effects Regression Example">
<meta property="og:description" content="hmclearn">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">hmclearn</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.0.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/linear_mixed_effects_hmclearn.html">hmclearn:  Linear Mixed Effects Regression Example</a>
    </li>
    <li>
      <a href="../articles/linear_regression_hmclearn.html">hmclearn:  Linear Regression Example</a>
    </li>
    <li>
      <a href="../articles/logistic_mixed_effects_hmclearn.html">hmclearn:  Logistic Mixed Effects Regression Example</a>
    </li>
    <li>
      <a href="../articles/logistic_regression_hmclearn.html">hmclearn:  Logistic Regression Example</a>
    </li>
    <li>
      <a href="../articles/poisson_regression_hmclearn.html">hmclearn:  Poisson Regression Example</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>hmclearn: Logistic Mixed Effects Regression Example</h1>
                        <h4 class="author">Samuel Thomas</h4>
            
            <h4 class="date">2020-06-10</h4>
      
      
      <div class="hidden name"><code>logistic_mixed_effects_hmclearn.Rmd</code></div>

    </div>

    
    
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>This vignette demonstrates fitting a Logistic mixed effects regression model via Hamiltonian Monte Carlo (HMC) using the <strong>hmclearn</strong> package.</p>
<p>For a mixed effects model with binary response, we let</p>
<p><span class="math display">\[
Pr(\mathbf{y} = \mathbf{1} | \mathbf{X}, \mathbf{Z}) = [1 + e^{-\mathbf{X}\boldsymbol\beta-\mathbf{Z} \mathbf{u} } ]^{-1},
\]</span> or</p>
<p><span class="math display">\[
\begin{aligned}
\text{logit}[P(\mathbf{y} = 1 | \mathbf{u})] &amp;= \mathbf{X}\boldsymbol\beta + \mathbf{Z}\mathbf{u}, \\
\mathbf{u} &amp;\sim N(0, \mathbf{G}).
\end{aligned}
\]</span></p>
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">hmclearn</span>)</pre></body></html></div>
<p>The response for each subject is a vector <span class="math inline">\(\mathbf{y} = (\mathbf{y}_1, ..., \mathbf{y}_n)\)</span> for <span class="math inline">\(n\)</span> subjects <span class="math inline">\(i= 1, ..., n\)</span>. Each subject has <span class="math inline">\(d\)</span> observations <span class="math inline">\(\mathbf{y}_i = (y_{i1}, ..., y_{id})\)</span> and we let <span class="math inline">\(j = 1, ..., d\)</span>. The fixed effect design matrix is composed of matrices for each subject, <span class="math inline">\(\mathbf{X} = (\mathbf{X}_1, ..., \mathbf{X}_n)\)</span>, and <span class="math inline">\(\mathbf{X}_i \in \mathbb{R}^{d\times (q+1)}\)</span> for the fixed effects parameters <span class="math inline">\(\boldsymbol\beta = (\beta_0, ..., \beta_q)\)</span>. The full fixed effects design matrix is therefore <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{nd \times (q+1)}\)</span>.</p>
<p>For random effects, <span class="math inline">\(\mathbf{Z} = \text{diag}(\mathbf{Z}_1, ..., \mathbf{Z}_n)\)</span>, with individual random effects matrices <span class="math inline">\(\mathbf{Z}_i\)</span> for each of the <span class="math inline">\(i\)</span> subjects. A random intercept model specifies <span class="math inline">\(\mathbf{Z}_i\)</span> as a column vector of ones where <span class="math inline">\(\mathbf{Z}_i = \mathbf{z}_i = \mathbf{1}_d\)</span>. The full random effects design matrix <span class="math inline">\(\mathbf{Z} \in \mathbb{R}^{nd\times n}\)</span>. The parameterization for random effects is <span class="math inline">\(\mathbf{u} = (\mathbf{u}_1, ..., \mathbf{u}_n)^T\)</span> with vectors <span class="math inline">\(\mathbf{u}_i\)</span> for each subject. A random intercept model is somewhat simplified where <span class="math inline">\(\mathbf{u}_i = u_i\)</span> denotes a single random intercept parameter for each subject <span class="math inline">\(i\)</span>, and <span class="math inline">\(\mathbf{u} = (u_1, ..., u_n)^T\)</span>.</p>
<p>We set <span class="math inline">\(\mathbf{u}\)</span> as one of our priors, following a multivariate normal distribution, <span class="math inline">\(\mathbf{u} \sim N(0, \mathbf{G})\)</span>. For our random intercept model, the specification of the covariance matrix <span class="math inline">\(\mathbf{G}\)</span> is expanded to facilitate efficient sampling using HMC. We let <span class="math inline">\(\mathbf{u} = \mathbf{G}^{1/2}\boldsymbol\tau\)</span> where <span class="math inline">\(\mathbf{G}^{1/2} = \lambda \mathbf{I}_n\)</span>. An additional parameter <span class="math inline">\(\boldsymbol\tau = (\tau_1, ..., \tau_n)^T\)</span> where each of these parameters is standard normal <span class="math inline">\(\tau_i \sim N(0, 1)\)</span>. The full covariance matrix is then <span class="math inline">\(\mathbf{G} = \lambda^2 \mathbf{I}_n \boldsymbol\tau\)</span>.</p>
<p>The parameterization approach for this model uses a strategy recommended by Betancourt, Girolami (2013) to facilitate more efficient sampling in HMC.</p>
<p>Further, we select a half-t family of distributions appropriate for hierarchical models per Gelman (2006). This parameterization is well-behaved around 0, in contrast to inverse gamma, and provides flexibility for informed priors.</p>
<p>We select a parameterization of <span class="math inline">\(\mathbf{G}\)</span> such that the likelihood and its gradient can be derived for HMC. To this end, we uses LDL decomposition of <span class="math inline">\(\mathbf{G}\)</span> to form a flexible parameterization that can easily handle restrictions (Chan, Jelizkov 2009).</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{u} &amp;\sim N(0, \mathbf{G}),  \\
\mathbf{G} &amp;= \mathbf{L} \mathbf{D} \mathbf{L}^T,  \\
&amp;= \mathbf{L} \mathbf{D}^{1/2} \mathbf{D}^{1/2} \mathbf{L}^T. \\
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(\boldsymbol{\lambda} = (\lambda_1, ..., \lambda_p)\)</span> denote the diagonal elements of <span class="math inline">\(\mathbf{D}^{1/2}\)</span> where <span class="math inline">\(p\)</span> indicates the number of random effect parameters, specified as <em>nrandom</em> in <strong>hmclearn</strong>. A future release of <strong>hmclearn</strong> will allow prior specification for the off-diagonal elements of <span class="math inline">\(L\)</span>. For the current version, we let <span class="math inline">\(L = I_{p}\)</span>.</p>
<p><span class="math display">\[
\mathbf{D}^{1/2} :=
\begin{pmatrix}
\lambda_1 &amp; 0 &amp; ... &amp; 0 \\
0 &amp; \lambda_2 &amp; 0 ... &amp; 0 \\
... &amp; ... &amp; ... &amp; ... \\
0 &amp; 0 &amp; ... &amp; \lambda_p
\end{pmatrix}, \quad
\mathbf{L} :=
\begin{pmatrix}
1 &amp; 0 &amp; 0 &amp; ... &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; ... &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; ... &amp; ... \\
... &amp; ... &amp; ... &amp; ... &amp; ... \\
0 &amp; 0 &amp; ... &amp; ... &amp; 1 \\
\end{pmatrix}.
\]</span></p>
<p>We set the prior for <span class="math inline">\(\boldsymbol\beta\)</span> as multivariate normal with variance <span class="math inline">\(\sigma_\beta^2\)</span>, a hyperparameter set by the analyst. The priors for <span class="math inline">\(\boldsymbol\lambda\)</span> are half-t per Gelman (2006) on hierarchical models.</p>
<p><span class="math display">\[
\begin{aligned}
\pi(\boldsymbol\beta | \sigma_\beta^2) &amp;\propto N(0, \sigma_\beta^2 \mathbf{I}), \\
\pi(\boldsymbol\lambda) &amp;\sim  \left(1 + \frac{1}{\nu_\lambda}\left(\frac{\boldsymbol\lambda}{A_\lambda} \right)^2 \right)^{-(\nu+1)/2}.
\end{aligned}
\]</span></p>
<p>We want proposals of <span class="math inline">\(\boldsymbol\lambda\)</span> over the real number line. Therfore we derive the distribution of the transformed parameter <span class="math inline">\(\boldsymbol\xi\)</span> based on a change of variable</p>
<p><span class="math display">\[
\begin{aligned}
\boldsymbol\xi &amp;:= \log\boldsymbol\lambda,  \\
\boldsymbol\lambda &amp;:= e^{\boldsymbol\xi}.
\end{aligned}
\]</span></p>
<p>We need to compute the Jacobian of the transformation</p>
<p><span class="math display">\[
\begin{aligned}
\pi_{\boldsymbol\xi}(\boldsymbol\xi) &amp;= \pi_{\boldsymbol\xi}(g^{-1}(\boldsymbol\xi)) \left\lvert \frac{d\boldsymbol\lambda}{d\boldsymbol\xi}  \right\rvert, \\
&amp;= \pi_{\boldsymbol\lambda} (e^{\boldsymbol\xi})\lvert e^{\boldsymbol\xi}\rvert, \\
&amp;= \left(1 + \frac{1}{\nu_\xi} \frac{e^{2\boldsymbol\xi}}{A_{\xi}^2}\right)^{-\frac{\nu_{\xi}+1}{2}}e^{\boldsymbol\xi}, \\
\log \pi(\boldsymbol\xi) &amp;\propto -\frac{\nu_{\xi}+1}{2}\log\left(1 + \frac{1}{\nu_{\xi}} \frac{e^{2\boldsymbol\xi}}{A_{\xi}^2}\right)+ \boldsymbol\xi.
\end{aligned}
\]</span></p>
</div>
<div id="derive-log-posterior-and-gradient-for-hmc" class="section level2">
<h2 class="hasAnchor">
<a href="#derive-log-posterior-and-gradient-for-hmc" class="anchor"></a>Derive log posterior and gradient for HMC</h2>
<p>First, we derive the likelihood for our logistic mixed effects regression model.</p>
<p><span class="math display">\[
\begin{aligned}
f(\mathbf{y}|\mathbf{X}, \mathbf{Z}, \boldsymbol\beta, \mathbf{u}) &amp;= \prod_{i=1}^n \prod_{j=1}^d p(y_{ij})^{y_{ij}}(1-p(y_{ij}))^{1-y_{ij}}, \\
&amp;= \prod_{i=1}^n \prod_{j=1}^d \left(\frac{1}{1 + e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i}} \right)^{y_{ij}}  \left( \frac{e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i}}{1+e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i}}  \right)^{1-y_{ij}},
 \\
\log f(\mathbf{y}|\mathbf{X}, \mathbf{Z}, \boldsymbol\beta, \mathbf{u}) &amp;= \sum_{i=1}^n \sum_{j=1}^d -y_{ij} \log\left(1+e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i} \right) + (1 - y_{ij})\log e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i} - (1 - y_{ij})\log\left(1+e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i} \right), \\
&amp;= \sum_{i=1}^n\sum_{j=1}^d -y_{ij} \log\left(1+e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}\mathbf{u}_i} \right) -\mathbf{x}_{ij}\boldsymbol\beta -\mathbf{z}_{ij}\mathbf{u}_i + y_{ij}\mathbf{x}_{ij}^T\boldsymbol\beta + y_{ij}\mathbf{z}_{ij}^T\mathbf{u}_i - \\
&amp;\qquad \log\left(1+e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i} \right) + y_{ij} \log\left(1+e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i} \right), \\
&amp;= \sum_{i=1}^n \sum_{j=1}^d -\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i + y_{ij}\mathbf{x}_{ij}^T\boldsymbol\beta + y_{ij}\mathbf{z}_{ij}^T\mathbf{u}_i - \log\left(1+e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i} \right), \\
&amp;= \sum_{i=1}^n \sum_{j=1}^d (y_{ij}-1 )(\mathbf{x}_{ij}^T\boldsymbol\beta + \mathbf{z}_{ij}^T\mathbf{u}_i) - \log\left(1+e^{-\mathbf{x}_{ij}^T\boldsymbol\beta - \mathbf{z}_{ij}^T\mathbf{u}_i} \right), \\
&amp;= (\mathbf{y} - \mathbf{1}_{nd})^T (\mathbf{X}\boldsymbol\beta + \mathbf{Z}\mathbf{u}) - \mathbf{1}_{nd}\log (1 + e^{-\mathbf{X}\boldsymbol\beta - \mathbf{Z}\mathbf{u}}).
\end{aligned}
\]</span></p>
<p>Additional notation is added to simplify the log likelihood, log posterior, and gradient formulations, <span class="math inline">\(\widetilde{\mathbf{D}}^{1/2} = \mathbf{I}_n \otimes \mathbf{D}^{1/2}\)</span>. Note that <span class="math inline">\(\widetilde{\mathbf{D}}^{1/2} = \left(\widetilde{\mathbf{D}}^{1/2}\right ) ^T\)</span> due to symmetry.</p>
<p>We write the re-parameterized log likelihood,</p>
<p><span class="math display">\[
\begin{aligned}
\log f(\mathbf{y}|\mathbf{X}, \mathbf{Z}, \boldsymbol\beta, \xi, \boldsymbol\tau) &amp;= (\mathbf{y} - \mathbf{1}_{nd})^T (\mathbf{X}\boldsymbol\beta + \mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau) - \mathbf{1}_{nd}\log (1 + e^{-\mathbf{X}\boldsymbol\beta - \mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}).
\end{aligned}
\]</span></p>
<p>Next, we express the log priors that we use with transformations, omitting constants. Note that the log densities of the priors with log densities include an additive term for the transformed distribution (i.e. <span class="math inline">\(\xi\)</span> and <span class="math inline">\(\gamma\)</span>),</p>
<p><span class="math display">\[
\begin{aligned}
\log \pi(\boldsymbol\beta | \sigma_\beta^2) &amp;\propto -\frac{\boldsymbol\beta^T \boldsymbol\beta}{2\sigma_\beta^2}, \\
\log \pi(\boldsymbol\xi | \nu_\xi, A_\xi) &amp;\propto -\frac{\nu_\xi + 1}{2} \log \left( 1 + \frac{1}{\nu_\xi} \left(\frac{e^\boldsymbol\xi}{A_\xi} \right)^2 \right) + \boldsymbol\xi, \\
\log \pi(\boldsymbol\tau) &amp;\propto -\frac{1}{2}\boldsymbol\tau^T \boldsymbol\tau.
\end{aligned}
\]</span></p>
<p>The full log posterior with transformed variables is the log likelihood plus the log prior. We develop the log posterior omitting constants,</p>
<p><span class="math display">\[
\begin{aligned}
\log f(\boldsymbol\beta, \xi, \boldsymbol\tau|\mathbf{y}, \mathbf{X}, \mathbf{Z}) &amp;\propto \log f(\mathbf{y}|\mathbf{X}, \mathbf{Z}, \boldsymbol\beta, \xi, \boldsymbol\tau) + \log f(\boldsymbol\beta, \xi, \boldsymbol\tau | \sigma_\beta^2, \nu_\xi, A_\xi), \\
&amp;\propto \log f(\mathbf{y}|\mathbf{X}, \mathbf{Z}, \boldsymbol\beta, \xi, \boldsymbol\tau) + \log f(\boldsymbol\beta | \sigma_\beta^2) + \log f(\xi | \nu_\xi, A_\xi) + \log f(\boldsymbol\tau), \\
&amp;\propto  (\mathbf{y} - \mathbf{1}_{nd})^T (\mathbf{X}\boldsymbol\beta + \mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau) - \mathbf{1}_{nd}^T\log (1 + e^{-\mathbf{X}\boldsymbol\beta - \mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau})  - \\ &amp;\qquad \frac{\boldsymbol\beta^T\boldsymbol\beta}{2\sigma_\beta^2}-\frac{\nu_\xi + 1}{2} \log \left( 1 + \frac{1}{\nu_\xi} \left(\frac{e^\xi}{A_\xi} \right)^2 \right) + \xi-\frac{1}{2}\boldsymbol\tau^T \boldsymbol\tau.
\end{aligned}
\]</span></p>
<p>Next we derive the gradient of the log posterior, comprised of partial derivatives for each of our parameters.</p>
<p>We omit <span class="math inline">\(\mathbf{L}\)</span> since this is currently defined as the identity matrix.</p>
<p>We derive the partial derivative of <span class="math inline">\(\boldsymbol\beta\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_\beta \log f(\boldsymbol\beta, \xi, \boldsymbol\tau | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\xi, A_\xi) &amp;\propto \mathbf{X}^T (\mathbf{y} - \mathbf{1}_{nd})+ \mathbf{X}^T \left[ 1 + e^{-\mathbf{X}\boldsymbol\beta - \mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau } \right]^{-1}e^{-\mathbf{X}\boldsymbol\beta-\mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau} - \boldsymbol\beta / \sigma_\beta^2, \\
&amp;\propto \mathbf{X}^T(\mathbf{y} - \mathbf{1}_{nd}) + \mathbf{X}^T \left(\frac{e^{-\mathbf{X}\boldsymbol\beta-\mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}}{1 + e^{-\mathbf{X}\boldsymbol\beta-\mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}} \right) - \boldsymbol\beta / \sigma_\beta^2, \\
&amp;\propto  \mathbf{X}^T(\mathbf{y} - \mathbf{1}_{nd}) + \mathbf{X}^T \left(\frac{1}{1 + e^{\mathbf{X}\boldsymbol\beta+\mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}} \right) - \boldsymbol\beta / \sigma_\beta^2,  \\
&amp;\propto \mathbf{X}^T \left( \mathbf{y} - \mathbf{1}_{nd} +\frac{1}{1 + e^{\mathbf{X}\boldsymbol\beta+\mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}} \right) - \boldsymbol\beta / \sigma_\beta^2.
\end{aligned}
\]</span></p>
<p>Next we derive the partial derivative of each parameter <span class="math inline">\(\xi_1, ..., \xi_p\)</span> where <span class="math inline">\(jj = 1, ..., p\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_{\xi_{jj} }\log f(\boldsymbol\beta, \xi_{jj}, \boldsymbol\tau| \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\xi, A_\xi)
&amp;\propto e^{\xi_{jj}} \boldsymbol\tau^T \mathbf{Z}^T (\mathbf{y} - \mathbf{1}_{nd})^T + e^{\xi_{jj}}\boldsymbol\tau^T\mathbf{Z}^T\left[1 + e^{-\mathbf{X}\boldsymbol\beta - e^{\xi_{jj}}\mathbf{Z}\boldsymbol\tau} \right ]^{-1} e^{-\mathbf{X}\boldsymbol\beta - e^{\xi_{jj}}\mathbf{Z}\boldsymbol\beta}
- \frac{\nu_\xi + 1}{1 + \nu_\xi A_\xi^2 e^{-2\xi_{jj}}} + 1, \\
&amp;\propto e^{\xi_{jj}} \boldsymbol\tau^T \mathbf{Z}^T(\mathbf{y} - \mathbf{1}_{nd})^T + e^{\xi_{jj}}\boldsymbol\tau^T\mathbf{Z}^T \left ( \frac{e^{-\mathbf{X}\boldsymbol\beta - e^{\xi_{jj}}\mathbf{Z}\boldsymbol\tau} }{1 + e^{-\mathbf{X}\boldsymbol\beta - e^{\xi_{jj}}\mathbf{Z}\boldsymbol\tau}}  \right)
- \frac{\nu_\xi + 1}{1 + \nu_\xi A_\xi^2 e^{-2\xi_{jj}}} + 1, \\
&amp;\propto e^{\xi_{jj}}\boldsymbol\tau^T \mathbf{Z}^T \left(\mathbf{y} - \mathbf{1}_{nd} +  \frac{1 }{1 + e^{\mathbf{X}\boldsymbol\beta + e^{\xi_{jj}}\mathbf{Z}\boldsymbol\tau}} \right )
- \frac{\nu_\xi + 1}{1 + \nu_\xi A_\xi^2 e^{-2\xi_{jj}}} + 1.
\end{aligned}
\]</span></p>
<p>Next, we derive the partial derivative of <span class="math inline">\(\boldsymbol\tau\)</span>,</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_\tau \log f(\boldsymbol\beta, \xi, \boldsymbol\tau | \mathbf{y}, \mathbf{X}, \mathbf{Z}, \sigma_\beta^2, \nu_\xi, A_\xi)
&amp;\propto \widetilde{\mathbf{D}}^{1/2}\mathbf{Z}^T (\mathbf{y} - \mathbf{1}_{nd}) + \widetilde{\mathbf{D}}^{1/2}\mathbf{Z}^T \left(\frac{e^{-\mathbf{X}\boldsymbol\beta-\mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}}{1 + e^{-\mathbf{X}\boldsymbol\beta-\mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}} \right)  - \tau \\
&amp;\propto \widetilde{\mathbf{D}}^{1/2}\mathbf{Z}^T \left(\mathbf{y} - \mathbf{1}_{nd} + \frac{1}{1 + e^{\mathbf{X}\boldsymbol\beta + \mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}} \right) - \tau .
\end{aligned}
\]</span></p>
<p>The gradient of full log posterior can now be specified,</p>
<p><span class="math display">\[
\begin{aligned}
\nabla_\beta \log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z})
&amp;\propto \mathbf{X}^T \left( \mathbf{y} - \mathbf{1}_{nd} +\frac{1}{1 + e^{\mathbf{X}\boldsymbol\beta+\mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}} \right) - \boldsymbol\beta / \sigma_\beta^2, \\
\nabla_{\xi_{jj}} \log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z})
&amp;\propto e^{\xi_{jj}}\mathbf{Z}\boldsymbol\tau \left(\mathbf{y} - \mathbf{1}_{nd} +  \frac{1 }{1 + e^{\mathbf{X}\boldsymbol\beta + e^{\xi_{jj}}\mathbf{Z}\boldsymbol\tau}} \right )
- \frac{\nu_\xi + 1}{1 + \nu_\xi A_\xi^2 e^{-2\xi_{jj}}} + 1,\quad \forall (\xi_1, ..., \xi_p) \in \boldsymbol\xi \\
\nabla_\tau \log f(\boldsymbol\beta, \xi, \boldsymbol\tau, \gamma | \mathbf{y}, \mathbf{X}, \mathbf{Z}) &amp;\propto \widetilde{\mathbf{D}}^{1/2}\mathbf{Z}^T \left(\mathbf{y} - \mathbf{1}_{nd} + \frac{1}{1 + e^{\mathbf{X}\boldsymbol\beta + \mathbf{Z}\widetilde{\mathbf{D}}^{1/2}\boldsymbol\tau}} \right) - \tau.
\end{aligned}
\]</span></p>
<p>Note that a random intercept model only has a single <span class="math inline">\(\xi\)</span> parameter, which simplifies the log posterior and gradient formulations. For a random intercept model, <span class="math inline">\(\widetilde{\mathbf{D}}^{1/2} = e^{\xi}\mathbf{I}_n\)</span>.</p>
</div>
<div id="logistic-mixed-effects-model-example-data" class="section level2">
<h2 class="hasAnchor">
<a href="#logistic-mixed-effects-model-example-data" class="anchor"></a>Logistic mixed effects model example data</h2>
<p>The user must define provide the design matrix directly for use in <strong>hmclearn</strong>. Our first step is to load the data and store the fixed effect design matrix <span class="math inline">\(\mathbf{X}\)</span>, random effects design matrix <span class="math inline">\(\mathbf{Z}\)</span>, and dependent variable vector <span class="math inline">\(y\)</span>.</p>
<p>We load drug Contraception data (Bates, et. al. 2014) and create the design matrices <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Z}\)</span> and dependent vector <span class="math inline">\(\mathbf{y}\)</span>. For this model, the random effects design matrix <span class="math inline">\(\mathbf{Z}\)</span> is specified for a random intercept model.</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="no">Contraception</span> <span class="kw">&lt;-</span> <span class="kw pkg">mlmRev</span><span class="kw ns">::</span><span class="no"><a href="https://rdrr.io/pkg/mlmRev/man/Contraception.html">Contraception</a></span>

<span class="no">Contraception</span>$<span class="no">liv2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span>(<span class="no">Contraception</span>$<span class="no">livch</span> <span class="kw">==</span> <span class="st">"0"</span>, <span class="fl">0</span>, <span class="fl">1</span>)

<span class="co">##########</span>
<span class="co"># block diagonal</span>
<span class="no">Zi.lst</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/split.html">split</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(<span class="no">Contraception</span>)), <span class="no">Contraception</span>$<span class="no">district</span>)
<span class="no">Zi.lst</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">Zi.lst</span>, <span class="no">as.matrix</span>)
<span class="no">Z</span> <span class="kw">&lt;-</span> <span class="kw pkg">Matrix</span><span class="kw ns">::</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/bdiag.html">bdiag</a></span>(<span class="no">Zi.lst</span>)
<span class="no">Z</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(<span class="no">Z</span>)

<span class="no">urban</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span>(<span class="no">Contraception</span>$<span class="no">urban</span> <span class="kw">==</span> <span class="st">"Y"</span>, <span class="fl">1</span>, <span class="fl">0</span>)

<span class="no">X</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(<span class="fl">1</span>, <span class="no">Contraception</span>$<span class="no">age</span>, <span class="no">Contraception</span>$<span class="no">age</span>^<span class="fl">2</span>, <span class="no">urban</span>, <span class="no">Contraception</span>$<span class="no">liv2</span>)
<span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">X</span>) <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"int"</span>, <span class="st">"age"</span>, <span class="st">"age_sq"</span>, <span class="st">"urban"</span>, <span class="st">"liv2"</span>)
<span class="no">y</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span>(<span class="no">Contraception</span>$<span class="no">use</span> <span class="kw">==</span> <span class="st">"Y"</span>, <span class="fl">1</span>, <span class="fl">0</span>)</pre></body></html></div>
</div>
<div id="qr-decomposition-of-design-matrix" class="section level2">
<h2 class="hasAnchor">
<a href="#qr-decomposition-of-design-matrix" class="anchor"></a>QR decomposition of design matrix</h2>
<p>To facilitate a more efficient fitting of the model, we apply QR decomposition to the fixed effects design matrix <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>Let <span class="math inline">\(\widetilde{\boldsymbol\beta} = R^*\boldsymbol\beta\)</span>, where <span class="math inline">\(\widetilde{\boldsymbol\beta}\)</span> is the transformed vector of <span class="math inline">\(\boldsymbol\beta\)</span>. The HMC estimates <span class="math inline">\(\widetilde{\boldsymbol\beta}\)</span>, from which we can use the deterministic formula to determine <span class="math inline">\(\boldsymbol\beta\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{X} &amp;= \mathbf{Q}^* \mathbf{R}^*, \quad \mathbf{Q}^* = \mathbf{Q} \cdot \sqrt{nd-1}, \quad \mathbf{R}^* = \frac{1}{\sqrt{nd-1}}\mathbf{R}, \\
\mathbf{X}\boldsymbol\beta &amp;= \mathbf{Q}^* \mathbf{R}^* \boldsymbol\beta \\
\boldsymbol\beta &amp;= \mathbf{R}^{*^{-1}}\widetilde{\boldsymbol\beta}, \quad \widetilde{\boldsymbol\beta} = \mathbf{R}^*\boldsymbol\beta
\end{aligned}
\]</span></p>
<p>We use the <em>qr</em> function from base <strong>R</strong> for our parameter transformation,</p>
<div class="sourceCode" id="cb3"><html><body><pre class="r"><span class="no">xqr</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/qr.html">qr</a></span>(<span class="no">X</span>)
<span class="no">Q</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/qraux.html">qr.Q</a></span>(<span class="no">xqr</span>)
<span class="no">R</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/qraux.html">qr.R</a></span>(<span class="no">xqr</span>)

<span class="no">n</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(<span class="no">X</span>)
<span class="no">X2</span> <span class="kw">&lt;-</span> <span class="no">Q</span> * <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="no">n</span>-<span class="fl">1</span>)
<span class="no">Rstar</span> <span class="kw">&lt;-</span> <span class="no">R</span> / <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="no">n</span>-<span class="fl">1</span>)
<span class="no">Rstar_inv</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span>(<span class="no">Rstar</span>)
<span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">X2</span>) <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"int"</span>, <span class="st">"age"</span>, <span class="st">"age_sq"</span>, <span class="st">"urban"</span>, <span class="st">"liv2"</span>)</pre></body></html></div>
<p>We could also apply QR decomposition to <span class="math inline">\(\mathbf{Z}\)</span>, but this is not necessary for a random intercept model where all elements of <span class="math inline">\(\mathbf{Z}\)</span> are 0 or 1.</p>
</div>
<div id="fit-model-using-hmc" class="section level2">
<h2 class="hasAnchor">
<a href="#fit-model-using-hmc" class="anchor"></a>Fit model using <em>hmc</em>
</h2>
<p>Next, we fit the linear mixed effects regression model using HMC. A vector of <em>tuning parameter</em> <span class="math inline">\(\epsilon\)</span> values are specified to align with the data. The hyperparameters for <span class="math inline">\(\nu_\xi\)</span> and <span class="math inline">\(A_\xi\)</span> are set to defaults in <strong>hmclearn</strong> (Gelman 2006). The hyperparameter <span class="math inline">\(\sigma_\beta^2\)</span> is set lower than the default based on the dependent variable variance for this hierarchical model.</p>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="no">N</span> <span class="kw">&lt;-</span> <span class="fl">2e3</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span>(<span class="fl">412</span>)
<span class="no">initvals</span><span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">0</span>, <span class="fl">5</span>), <span class="co"># fixed effects</span>
                <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">0</span>, <span class="fl">60</span>), <span class="co"># random intercepts</span>
                <span class="fl">0</span>) <span class="co"># variance of random intercepts</span>

<span class="no">vnames</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">X</span>),
            <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span>(<span class="st">"tau_int"</span>, <span class="fl">1</span>:<span class="fl">60</span>),
            <span class="st">"xi"</span>)

<span class="no">epsvals</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">5e-2</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">1e-2</span>, <span class="fl">4</span>), <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">5e-2</span>, <span class="fl">61</span>))

<span class="no">t1.hmc</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html">Sys.time</a></span>()
<span class="no">f_hmc</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/hmc.html">hmc</a></span>(<span class="kw">N</span> <span class="kw">=</span> <span class="no">N</span>, <span class="kw">theta.init</span> <span class="kw">=</span> <span class="no">initvals</span>,
             <span class="kw">epsilon</span> <span class="kw">=</span> <span class="no">epsvals</span>, <span class="kw">L</span> <span class="kw">=</span> <span class="fl">10</span>,
             <span class="kw">logPOSTERIOR</span> <span class="kw">=</span> <span class="no">glmm_bin_posterior</span>,
             <span class="kw">glogPOSTERIOR</span> <span class="kw">=</span> <span class="no">g_glmm_bin_posterior</span>,
             <span class="kw">varnames</span> <span class="kw">=</span> <span class="no">vnames</span>,
             <span class="kw">parallel</span><span class="kw">=</span><span class="fl">FALSE</span>, <span class="kw">chains</span><span class="kw">=</span><span class="fl">2</span>,
             <span class="kw">param</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">y</span>, <span class="kw">X</span><span class="kw">=</span><span class="no">X2</span>, <span class="kw">Z</span><span class="kw">=</span><span class="no">Z</span>, <span class="kw">n</span><span class="kw">=</span><span class="fl">60</span>, <span class="kw">nrandom</span><span class="kw">=</span><span class="fl">1</span>, <span class="kw">sig2beta</span><span class="kw">=</span><span class="fl">5</span>,
                        <span class="kw">nuxi</span><span class="kw">=</span><span class="fl">1</span>, <span class="kw">Axi</span><span class="kw">=</span><span class="fl">25</span>)  )


<span class="no">t2.hmc</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html">Sys.time</a></span>()
<span class="no">t2.hmc</span> - <span class="no">t1.hmc</span>
<span class="co">#&gt; Time difference of 11.52061 mins</span></pre></body></html></div>
<p>The acceptance ratio for each of the HMC chains is sufficiently high for an efficient simulation.</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="no">f_hmc</span>$<span class="no">accept</span>/<span class="no">N</span>
<span class="co">#&gt; [1] 0.670 0.672</span></pre></body></html></div>
<p>Since we used QR decomposition to transform <span class="math inline">\(\beta\)</span> prior to fitting via HMC, we need to reverse the transformation to obtain the original parameter scale.</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="co"># restore beta from Rstar in QR decomposition</span>
<span class="no">calc_beta</span> <span class="kw">&lt;-</span> <span class="kw">function</span>(<span class="no">beta_tilde_param</span>, <span class="no">Rstarinv</span>) {
  <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(<span class="no">Rstarinv</span> <span class="kw">%*%</span> <span class="no">beta_tilde_param</span>)
}

<span class="co"># reverse qr decomposition</span>
<span class="no">f_hmc2</span> <span class="kw">&lt;-</span> <span class="no">f_hmc</span>
<span class="no">f_hmc2</span>$<span class="no">thetaCombined</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span>, <span class="kw">function</span>(<span class="no">xx</span>) {
  <span class="no">xx</span>[, <span class="fl">1</span>:<span class="fl">5</span>] <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(<span class="no">xx</span>[, <span class="fl">1</span>:<span class="fl">5</span>], <span class="fl">1</span>, <span class="no">calc_beta</span>, <span class="kw">Rstarinv</span><span class="kw">=</span><span class="no">Rstar_inv</span>))
  <span class="no">xx</span>
})</pre></body></html></div>
<p>The posterior quantiles are summarized after removing an initial <em>burnin</em> period. The <span class="math inline">\(\hat{R}\)</span> statistics are close to one, indicating that both HMC chains converged to the same distribution. The <span class="math inline">\(\hat{R}\)</span> statistics provide an indication of convergence. Values close to one indicate that the multiple MCMC chains converged to the same distribution, while values above 1.1 indicate possible convergence problems. All <span class="math inline">\(\hat{R}\)</span> values in our example are close to one.</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">f_hmc2</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fl">1000</span>, <span class="kw">probs</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0.025</span>, <span class="fl">0.5</span>, <span class="fl">0.975</span>))
<span class="co">#&gt; Summary of MCMC simulation</span>
<span class="co">#&gt;                   2.5%          50%        97.5%      rhat</span>
<span class="co">#&gt; int       -1.347499845 -1.002604446 -0.659497972 1.0014634</span>
<span class="co">#&gt; age       -0.009255767  0.006563724  0.020626589 1.0003654</span>
<span class="co">#&gt; age_sq    -0.006148684 -0.004683696 -0.003223872 1.0000839</span>
<span class="co">#&gt; urban      0.452351900  0.683275458  0.929803088 1.0076632</span>
<span class="co">#&gt; liv2       0.572722550  0.862870463  1.179121304 0.9997327</span>
<span class="co">#&gt; tau_int1  -2.465594898 -1.504566068 -0.660800597 1.0021200</span>
<span class="co">#&gt; tau_int2  -1.405244265 -0.046077600  1.353882998 0.9995182</span>
<span class="co">#&gt; tau_int3  -1.168076289  0.654959461  2.470604063 1.0133501</span>
<span class="co">#&gt; tau_int4  -0.784816167  0.369202243  1.513985214 0.9998724</span>
<span class="co">#&gt; tau_int5  -0.928682332  0.183618830  1.251809351 1.0080292</span>
<span class="co">#&gt; tau_int6  -1.481844791 -0.476888752  0.431850829 0.9995249</span>
<span class="co">#&gt; tau_int7  -1.747265505 -0.370917817  0.905435106 1.0076276</span>
<span class="co">#&gt; tau_int8  -0.854870796  0.292412315  1.482049428 1.0110102</span>
<span class="co">#&gt; tau_int9  -1.644541148 -0.378372534  0.913598514 1.0005747</span>
<span class="co">#&gt; tau_int10 -2.491775084 -0.682888192  0.954067631 1.0043927</span>
<span class="co">#&gt; tau_int11 -3.182466810 -1.658293490 -0.215434474 1.0022619</span>
<span class="co">#&gt; tau_int12 -1.600677101 -0.231618403  0.975786439 1.0017680</span>
<span class="co">#&gt; tau_int13 -1.170293314  0.169942826  1.320548092 1.0056639</span>
<span class="co">#&gt; tau_int14  0.486206193  1.315717615  2.241188249 1.0000029</span>
<span class="co">#&gt; tau_int15 -1.325409211 -0.120115440  1.102520071 1.0000940</span>
<span class="co">#&gt; tau_int16  0.074031338  1.309742660  2.663588823 1.0212303</span>
<span class="co">#&gt; tau_int17 -1.744419658 -0.351410830  0.881922589 1.0369249</span>
<span class="co">#&gt; tau_int18 -1.157279994 -0.065710778  1.011665802 1.0059568</span>
<span class="co">#&gt; tau_int19 -1.245115805  0.122116020  1.394560353 1.0158353</span>
<span class="co">#&gt; tau_int20 -1.027153714  0.426563713  1.849936129 1.0071624</span>
<span class="co">#&gt; tau_int21 -1.254942685  0.017976116  1.351423801 1.0192542</span>
<span class="co">#&gt; tau_int22 -2.332778090 -0.888691670  0.431605057 0.9998864</span>
<span class="co">#&gt; tau_int23 -2.000875433 -0.385289018  1.042722201 1.0026830</span>
<span class="co">#&gt; tau_int24 -2.646888057 -1.094847369  0.434614968 1.0117203</span>
<span class="co">#&gt; tau_int25 -0.667098400  0.277855404  1.127194544 0.9995049</span>
<span class="co">#&gt; tau_int26 -1.445290053  0.002781515  1.478335030 1.0561882</span>
<span class="co">#&gt; tau_int27 -2.132949357 -0.941302524  0.196168094 1.0019260</span>
<span class="co">#&gt; tau_int28 -1.734535718 -0.632972869  0.451512898 1.0019482</span>
<span class="co">#&gt; tau_int29 -1.569143502 -0.345303107  0.857115138 1.0011194</span>
<span class="co">#&gt; tau_int30 -0.131177086  0.875944519  1.882620898 1.0001374</span>
<span class="co">#&gt; tau_int31 -0.377730313  0.733064073  1.872115600 1.0141730</span>
<span class="co">#&gt; tau_int32 -2.258770246 -0.946487116  0.344841171 0.9995009</span>
<span class="co">#&gt; tau_int33 -1.574454654 -0.093608793  1.469875984 1.0019248</span>
<span class="co">#&gt; tau_int34  0.232098236  1.403767991  2.698852531 1.0184362</span>
<span class="co">#&gt; tau_int35 -0.477469395  0.513052067  1.514391502 0.9995147</span>
<span class="co">#&gt; tau_int36 -1.811149118 -0.297759332  1.178609170 1.0004970</span>
<span class="co">#&gt; tau_int37 -0.652864004  0.633495509  1.949085951 1.0026299</span>
<span class="co">#&gt; tau_int38 -1.575129436 -0.124136610  1.308530565 1.0231211</span>
<span class="co">#&gt; tau_int39 -0.303975919  1.037111743  2.273527703 1.0011847</span>
<span class="co">#&gt; tau_int40 -0.819018408  0.223307506  1.206773302 0.9997188</span>
<span class="co">#&gt; tau_int41 -0.757190334  0.427436139  1.556769074 0.9998307</span>
<span class="co">#&gt; tau_int42 -1.119880954  0.573428964  2.067500829 1.0195341</span>
<span class="co">#&gt; tau_int43  0.067577505  1.075004927  2.100332841 1.0016600</span>
<span class="co">#&gt; tau_int44 -1.894670996 -0.613922594  0.507643758 1.0057337</span>
<span class="co">#&gt; tau_int45 -1.414879962 -0.245333852  0.919593280 1.0018127</span>
<span class="co">#&gt; tau_int46  0.251684442  1.101175417  2.027513018 1.0094651</span>
<span class="co">#&gt; tau_int47 -1.007326126  0.377783628  1.784483404 1.0095375</span>
<span class="co">#&gt; tau_int48 -0.144092330  0.862074276  1.879188549 1.0107926</span>
<span class="co">#&gt; tau_int49 -2.130213651 -0.376494856  1.278222364 1.0118307</span>
<span class="co">#&gt; tau_int50 -0.827109771  0.472012275  1.807589669 0.9998834</span>
<span class="co">#&gt; tau_int51 -0.911076928  0.229237417  1.434753593 1.0006495</span>
<span class="co">#&gt; tau_int52 -0.433086014  0.453052678  1.325939296 1.0033275</span>
<span class="co">#&gt; tau_int53 -1.615030500 -0.315416767  1.109049230 1.0003612</span>
<span class="co">#&gt; tau_int54 -2.532241593 -0.956410434  0.605607306 0.9997552</span>
<span class="co">#&gt; tau_int55  0.156492872  1.202533184  2.291453242 0.9995593</span>
<span class="co">#&gt; tau_int56 -2.350742836 -1.025277907  0.234839832 0.9996233</span>
<span class="co">#&gt; tau_int57 -0.653381781  0.583648022  1.781793202 1.0052080</span>
<span class="co">#&gt; tau_int58 -2.448971701 -0.709517372  0.857475449 1.0001395</span>
<span class="co">#&gt; tau_int59 -2.231796487 -0.838218291  0.315858751 1.0011856</span>
<span class="co">#&gt; tau_int60 -2.319355056 -1.042270086  0.124104647 0.9997774</span>
<span class="co">#&gt; xi        -1.033553459 -0.662905154 -0.343340191 1.0022953</span></pre></body></html></div>
<p>We create trace plots on the transformed simulation data.</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="fu"><a href="../reference/hmclearn-plots.html">mcmc_trace</a></span>(<span class="no">f_hmc2</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fl">1000</span>, <span class="kw">pars</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">X</span>))</pre></body></html></div>
<div class="figure">
<img src="fig1glmm-1.png" alt=""><p class="caption">plot of chunk fig1glmm</p>
</div>
</div>
<div id="comparison-model---frequentist" class="section level2">
<h2 class="hasAnchor">
<a href="#comparison-model---frequentist" class="anchor"></a>Comparison model - Frequentist</h2>
<p>To compare results, we first fit a logistic mixed effects model using the frequentist package <strong>lme4</strong> (Bates et. al. 2015).</p>
<div class="sourceCode" id="cb9"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">lme4</span>)

<span class="no">fm1</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/glmer.html">glmer</a></span>(<span class="no">use</span> ~ <span class="no">age</span> + <span class="fu"><a href="https://rdrr.io/r/base/AsIs.html">I</a></span>(<span class="no">age</span>^<span class="fl">2</span>) + <span class="no">urban</span> + <span class="no">liv2</span> + (<span class="fl">1</span> <span class="kw">|</span> <span class="no">district</span>),
           <span class="kw">data</span><span class="kw">=</span><span class="no">Contraception</span>, <span class="kw">family</span><span class="kw">=</span><span class="no">binomial</span>,
           <span class="kw">control</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/pkg/lme4/man/lmerControl.html">glmerControl</a></span>(<span class="kw">optCtrl</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="kw">maxfun</span><span class="kw">=</span><span class="fl">20000</span>)))
<span class="co">#&gt; Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue</span>
<span class="co">#&gt;  - Rescale variables?</span>
<span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(<span class="no">fm1</span>)
<span class="co">#&gt; Generalized linear mixed model fit by maximum likelihood (Laplace</span>
<span class="co">#&gt;   Approximation) [glmerMod]</span>
<span class="co">#&gt;  Family: binomial  ( logit )</span>
<span class="co">#&gt; Formula: use ~ age + I(age^2) + urban + liv2 + (1 | district)</span>
<span class="co">#&gt;    Data: Contraception</span>
<span class="co">#&gt; Control: glmerControl(optCtrl = list(maxfun = 20000))</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;      AIC      BIC   logLik deviance df.resid </span>
<span class="co">#&gt;   2385.2   2418.6  -1186.6   2373.2     1928 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Scaled residuals: </span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -1.8151 -0.7620 -0.4619  0.9518  3.1033 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Random effects:</span>
<span class="co">#&gt;  Groups   Name        Variance Std.Dev.</span>
<span class="co">#&gt;  district (Intercept) 0.2247   0.474   </span>
<span class="co">#&gt; Number of obs: 1934, groups:  district, 60</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Fixed effects:</span>
<span class="co">#&gt;               Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept) -1.0063737  0.1691107  -5.951 2.67e-09 ***</span>
<span class="co">#&gt; age          0.0062561  0.0078848   0.793    0.428    </span>
<span class="co">#&gt; I(age^2)    -0.0046353  0.0007207  -6.432 1.26e-10 ***</span>
<span class="co">#&gt; urbanY       0.6929220  0.1206566   5.743 9.31e-09 ***</span>
<span class="co">#&gt; liv2         0.8603821  0.1483014   5.802 6.57e-09 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Correlation of Fixed Effects:</span>
<span class="co">#&gt;          (Intr) age    I(g^2) urbanY</span>
<span class="co">#&gt; age       0.529                     </span>
<span class="co">#&gt; I(age^2) -0.533 -0.506              </span>
<span class="co">#&gt; urbanY   -0.259 -0.032  0.020       </span>
<span class="co">#&gt; liv2     -0.801 -0.565  0.345  0.094</span>
<span class="co">#&gt; convergence code: 0</span>
<span class="co">#&gt; Model is nearly unidentifiable: very large eigenvalue</span>
<span class="co">#&gt;  - Rescale variables?</span></pre></body></html></div>
<div class="sourceCode" id="cb10"><html><body><pre class="r">
<span class="no">freqvals</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(<span class="fu"><a href="https://rdrr.io/pkg/lme4/man/fixef.html">fixef</a></span>(<span class="no">fm1</span>)),
              <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(<span class="fu"><a href="https://rdrr.io/pkg/lme4/man/ranef.html">ranef</a></span>(<span class="no">fm1</span>)$<span class="no">district</span>[, <span class="fl">1</span>]),
              <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(<span class="fu"><a href="https://rdrr.io/pkg/lme4/man/VarCorr.html">VarCorr</a></span>(<span class="no">fm1</span>)[<span class="fl">1</span>]))))</pre></body></html></div>
<p>Histograms of the posterior distribution show that Bayesian parameter estimates align with frequentist estimates. The <em>cols</em> parameter specifies the parameters to be displayed in <em>diagplots</em>, based on the order provided to the <em>hmc</em> function.</p>
<div class="sourceCode" id="cb11"><html><body><pre class="r"><span class="fu"><a href="../reference/diagplots.html">diagplots</a></span>(<span class="no">f_hmc2</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fl">1000</span>,
          <span class="kw">comparison.theta</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="no">freqvals</span>[<span class="fl">1</span>:<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span>(<span class="no">X</span>)],
                             <span class="no">freqvals</span>[<span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">freqvals</span>)]),
          <span class="kw">cols</span><span class="kw">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">1</span>:<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span>(<span class="no">X</span>), <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span>(<span class="no">initvals</span>)))
<span class="co">#&gt; $histogram</span></pre></body></html></div>
<div class="figure">
<img src="fig2glmm-1.png" alt=""><p class="caption">plot of chunk fig2glmm</p>
</div>
<p>We also compare the random effects parameter estimates with <strong>lme4</strong>. We apply the linear transformation back to <span class="math inline">\(\mathbf{u}\)</span> for comparison.</p>
<div class="sourceCode" id="cb12"><html><body><pre class="r"><span class="no">u.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lme4/man/ranef.html">ranef</a></span>(<span class="no">fm1</span>)$<span class="no">district</span>[, <span class="fl">1</span>]
<span class="no">lambda.freq</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="fu"><a href="https://rdrr.io/pkg/lme4/man/VarCorr.html">VarCorr</a></span>(<span class="no">fm1</span>)$<span class="no">district</span>[<span class="fl">1</span>])

<span class="co"># transform parameters back to original scale</span>
<span class="no">f_hmc</span>$<span class="no">thetaCombined</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span>, <span class="kw">function</span>(<span class="no">xx</span>) {
  <span class="no">tau_mx</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(<span class="no">xx</span>[, <span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"tau"</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">xx</span>))])
  <span class="no">u_mx</span> <span class="kw">&lt;-</span> <span class="no">tau_mx</span> * <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span>(<span class="no">xx</span>[, <span class="st">"xi"</span>])
  <span class="no">u_df</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span>(<span class="no">u_mx</span>)
  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">u_df</span>) <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span>(<span class="st">"u"</span>, <span class="fl">1</span>:<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span>(<span class="no">u_df</span>))
  <span class="no">xx</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(<span class="no">xx</span>, <span class="no">u_df</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span>(<span class="no">xx</span>[, <span class="st">"xi"</span>]))
  <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">xx</span>)[<span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span>(<span class="no">xx</span>)] <span class="kw">&lt;-</span> <span class="st">"lambda"</span>
  <span class="no">xx</span>
})</pre></body></html></div>
<p>Since we have 60 random effect parameters plus <span class="math inline">\(\lambda\)</span>, we split the plots into more manageable chunks. The random effects parameters align with frequentist estimates.</p>
<div class="sourceCode" id="cb13"><html><body><pre class="r"><span class="co"># histograms with lines for frequentist estimates</span>
<span class="no">ucols</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"^[u](?:[1-9]|0[1-9]|1[0-9]|20)$"</span>,
                     <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span><span class="kw">[[</span><span class="fl">1</span>]])))
<span class="no">lambdacol</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"^lambda"</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span><span class="kw">[[</span><span class="fl">1</span>]])))
<span class="fu"><a href="../reference/diagplots.html">diagplots</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fl">1000</span>,
          <span class="kw">comparison.theta</span> <span class="kw">=</span> <span class="no">u.freq</span>[<span class="fl">1</span>:<span class="fl">20</span>], <span class="kw">cols</span> <span class="kw">=</span> <span class="no">ucols</span>)
<span class="co">#&gt; $histogram</span></pre></body></html></div>
<div class="figure">
<img src="fig3glmm-1.png" alt=""><p class="caption">plot of chunk fig3glmm</p>
</div>
<div class="sourceCode" id="cb14"><html><body><pre class="r"><span class="co"># histograms with lines for frequentist estimates</span>
<span class="no">ucols</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"^[u](?:2[1-9]|3[0-9]|40)$"</span>,
                     <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span><span class="kw">[[</span><span class="fl">1</span>]])))
<span class="no">lambdacol</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"^lambda"</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span><span class="kw">[[</span><span class="fl">1</span>]])))
<span class="fu"><a href="../reference/diagplots.html">diagplots</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fl">1000</span>,
          <span class="kw">comparison.theta</span> <span class="kw">=</span> <span class="no">u.freq</span>[<span class="fl">21</span>:<span class="fl">40</span>], <span class="kw">cols</span> <span class="kw">=</span> <span class="no">ucols</span>)
<span class="co">#&gt; $histogram</span></pre></body></html></div>
<div class="figure">
<img src="fig4glmm-1.png" alt=""><p class="caption">plot of chunk fig4glmm</p>
</div>
<div class="sourceCode" id="cb15"><html><body><pre class="r"><span class="co"># histograms with lines for frequentist estimates</span>
<span class="no">ucols</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"^[u](?:4[1-9]|5[0-9]|60)$"</span>,
                     <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span><span class="kw">[[</span><span class="fl">1</span>]])))
<span class="no">lambdacol</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/grep.html">grepl</a></span>(<span class="st">"^lambda"</span>, <span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span>(<span class="no">f_hmc</span>$<span class="no">thetaCombined</span><span class="kw">[[</span><span class="fl">1</span>]])))
<span class="fu"><a href="../reference/diagplots.html">diagplots</a></span>(<span class="no">f_hmc</span>, <span class="kw">burnin</span><span class="kw">=</span><span class="fl">1000</span>,
          <span class="kw">comparison.theta</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="no">u.freq</span>[<span class="fl">41</span>:<span class="fl">60</span>], <span class="no">lambda.freq</span>), <span class="kw">cols</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="no">ucols</span>, <span class="no">lambdacol</span>))
<span class="co">#&gt; $histogram</span></pre></body></html></div>
<div class="figure">
<img src="fig5glmm-1.png" alt=""><p class="caption">plot of chunk fig5glmm</p>
</div>
</div>
<div id="source" class="section level2">
<h2 class="hasAnchor">
<a href="#source" class="anchor"></a>Source</h2>
<p>Steele, F., Diamond, I. And Amin, S. (1996). Immunization uptake in rural Bangladesh: a multilevel analysis. <em>Journal of the Royal Statistical Society</em>, Series A (159): 289-299.</p>
<p></p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<p>Bates, D., Mächler, M., Bolker, B., &amp; Walker, S. (2015). Fitting linear mixed-effects models using lme4. <em>Journal of Statistical Software</em> 67(1)</p>
<p>Bates, D., Mächler, M., &amp; Bolker, B. (2014). mlmRev: Examples from multilevel modelling software review. <em>R package version, 1</em>.</p>
<p>Agresti, A. (2015). <em>Foundations of linear and generalized linear models</em>. John Wiley &amp; Sons. ISBN: 978-1-118-73003-4</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Samuel Thomas.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.9000.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
